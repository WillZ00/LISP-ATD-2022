{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1a5591",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92827dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import atd2022\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from atd_informer import atd_informer\n",
    "from utils.tools import dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dd46b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'atd_informer.atd_informer' from '/Users/will/Desktop/LISP-ATD-2022/Informer/atd_informer/atd_informer.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(atd_informer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9b8a5",
   "metadata": {},
   "source": [
    "# Model Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86b3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "\n",
    "args.enc_in = 5200 # encoder input size\n",
    "args.dec_in = 5200 # decoder input size\n",
    "args.c_out = 5200 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.freq = 'w'\n",
    "args.inverse=False\n",
    "args.timeenc=0\n",
    "args.checkpoints = \"/Users/will/Desktop/tmp\"\n",
    "\n",
    "\n",
    "\n",
    "args.seq_len=8\n",
    "args.label_len=4\n",
    "args.pred_len=2\n",
    "\n",
    "\n",
    "args.batch_size = 1\n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False\n",
    "\n",
    "args.itr=1\n",
    "args.train_epochs=2\n",
    "args.patience=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64fedfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "informer = atd_informer.ATD_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb2660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6a523c5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38fc8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      ">>>>>>>start training : None_None_ftNone_sl8_ll4_pl2_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_None_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\titers: 100, epoch: 1 | loss: 4701306.5000000\n",
      "\tspeed: 0.1951s/iter; left time: 118.2435s\n",
      "Epoch: 1 cost time: 27.57057213783264\n",
      "Epoch: 1, Steps: 141 | Train Loss: 3713178.0088652 Vali Loss: 5027999.0000000 Test Loss: 3626836.5000000\n",
      "Validation loss decreased (inf --> 5027999.000000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 4697141.0000000\n",
      "\tspeed: 0.2902s/iter; left time: 134.9531s\n",
      "Epoch: 2 cost time: 27.324424028396606\n",
      "Epoch: 2, Steps: 141 | Train Loss: 3709560.9317376 Vali Loss: 5023769.0000000 Test Loss: 3623204.2500000\n",
      "Validation loss decreased (5027999.000000 --> 5023769.000000).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 4694230.5000000\n",
      "\tspeed: 0.2888s/iter; left time: 93.5771s\n",
      "Epoch: 3 cost time: 27.439446926116943\n",
      "Epoch: 3, Steps: 141 | Train Loss: 3706783.9734043 Vali Loss: 5021604.0000000 Test Loss: 3621346.2500000\n",
      "Validation loss decreased (5023769.000000 --> 5021604.000000).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 4692798.0000000\n",
      "\tspeed: 0.2885s/iter; left time: 52.7963s\n",
      "Epoch: 4 cost time: 27.16781997680664\n",
      "Epoch: 4, Steps: 141 | Train Loss: 3705383.4175532 Vali Loss: 5020521.5000000 Test Loss: 3620418.2500000\n",
      "Validation loss decreased (5021604.000000 --> 5020521.500000).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 4692063.5000000\n",
      "\tspeed: 0.2881s/iter; left time: 12.0990s\n",
      "Epoch: 5 cost time: 27.124332904815674\n",
      "Epoch: 5, Steps: 141 | Train Loss: 3704686.3519504 Vali Loss: 5019983.0000000 Test Loss: 3619956.5000000\n",
      "Validation loss decreased (5020521.500000 --> 5019983.000000).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      ">>>>>>>testing : None_None_ftNone_sl8_ll4_pl2_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_None_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test shape: (42, 1, 2, 5200) (42, 1, 2, 5200)\n",
      "test shape: (42, 2, 5200) (42, 2, 5200)\n",
      "mse:3619957.0, mae:214.6122589111328\n"
     ]
    }
   ],
   "source": [
    "for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = informer(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a47a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7713b40c",
   "metadata": {},
   "source": [
    "# Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20df2236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Replacement index 17 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m setting \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_ft\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_sl\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_ll\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_pl\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_dm\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_nh\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_el\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_dl\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_df\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_at\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_fc\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_eb\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_dt\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_mx\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                                                                     \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                                                     \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                                                     \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                                                     \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 17 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                                                                                                     args.seq_len, args.label_len, args.pred_len,\n",
    "                                                                                                     args.d_model, args.n_heads, args.e_layers, args.d_layers,\n",
    "                                                                                                     args.d_ff, args.attn, args.factor, args.embed, args.distil, \n",
    "                                                                                                     args.mix, args.des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4b56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting= \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9b26c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset_Pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/LISP-ATD-2022/Informer/atd_informer/atd_informer.py:223\u001b[0m, in \u001b[0;36mATD_Informer.predict\u001b[0;34m(self, setting, load)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, setting, load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 223\u001b[0m     pred_data, pred_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m    226\u001b[0m         path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mcheckpoints, setting)\n",
      "File \u001b[0;32m~/Desktop/LISP-ATD-2022/Informer/atd_informer/atd_informer.py:66\u001b[0m, in \u001b[0;36mATD_Informer._get_data\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m flag\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     65\u001b[0m     shuffle_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m; drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m; batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m; freq\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdetail_freq\n\u001b[0;32m---> 66\u001b[0m     Data \u001b[38;5;241m=\u001b[39m \u001b[43mDataset_Pred\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     shuffle_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m; drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m; batch_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mbatch_size; freq\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mfreq\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset_Pred' is not defined"
     ]
    }
   ],
   "source": [
    "exp.predict(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74278886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atd2022",
   "language": "python",
   "name": "atd2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
