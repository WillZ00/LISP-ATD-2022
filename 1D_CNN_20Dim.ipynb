{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3aa36b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_mod' from 'C:\\\\Users\\\\Work Space\\\\atd2022\\\\code\\\\my_mod.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import atd2022\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import my_mod as util\n",
    "import importlib\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67445cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966aeba",
   "metadata": {},
   "source": [
    "# 1-dim CNN experiment on 20-dim time series vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f60cbe",
   "metadata": {},
   "source": [
    "# Data Import/Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88943f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = atd2022.io.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43bf8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_region=data[\"AA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a14bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e966e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "506fa411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Event</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01/2018-01-07</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08/2018-01-14</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-15/2018-01-21</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22/2018-01-28</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29/2018-02-04</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05/2018-02-11</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Event                  01  02  03  04  05  06  07  08  09  10  11  12  13  14  \\\n",
       "2018-01-01/2018-01-07   7   5  26  22   5   0   0   1   1   0   3   1   0   0   \n",
       "2018-01-08/2018-01-14  13   9  20  85   4   2   0   2   8   0   0   0   0   0   \n",
       "2018-01-15/2018-01-21  14   5   8  10   1   0   0   1   0   1   0   1   0   0   \n",
       "2018-01-22/2018-01-28   5   2   0  23   3   2   5   1   0   0   2   0   0   0   \n",
       "2018-01-29/2018-02-04   3   2   7  37   6  10   4   7   0   1   1   1   0   0   \n",
       "2018-02-05/2018-02-11   7   6   7  49   6   0   1   2   2   2   6   0   1   0   \n",
       "\n",
       "Event                  15  16  17  18  19  20  \n",
       "2018-01-01/2018-01-07   0   0   1   0   0   0  \n",
       "2018-01-08/2018-01-14   0   1   8   0   0   0  \n",
       "2018-01-15/2018-01-21   0   0   3   0   2   0  \n",
       "2018-01-22/2018-01-28   0   3   4   0   4   0  \n",
       "2018-01-29/2018-02-04   0   0   0   0   0   0  \n",
       "2018-02-05/2018-02-11   0   0   2   0   4   0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_region.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fba19885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "test=util.getMultiDXY(test_region, n_lags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4954d287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 3., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [5., 2., 0., ..., 0., 4., 0.],\n",
       "       [3., 2., 7., ..., 0., 0., 0.],\n",
       "       [7., 6., 7., ..., 0., 4., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c30dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 3., 7., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47e0f026",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y = util.getMultiDXY(test_region, n_lags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d60c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "935efc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 2.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 2.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  3., ...,  0.,  1.,  0.]],\n",
       "\n",
       "       [[ 0.,  1.,  3., ...,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[13.,  9., 20., ...,  0.,  0.,  0.],\n",
       "        [14.,  5.,  8., ...,  0.,  2.,  0.]],\n",
       "\n",
       "       [[14.,  5.,  8., ...,  0.,  2.,  0.],\n",
       "        [ 5.,  2.,  0., ...,  0.,  4.,  0.]],\n",
       "\n",
       "       [[ 5.,  2.,  0., ...,  0.,  4.,  0.],\n",
       "        [ 3.,  2.,  7., ...,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "410a189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  3., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 6.,  1., 59., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 5.,  2.,  0., ...,  0.,  4.,  0.],\n",
       "       [ 3.,  2.,  7., ...,  0.,  0.,  0.],\n",
       "       [ 7.,  6.,  7., ...,  0.,  4.,  0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8c81de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3a7ed1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 2, 20)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4c49da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (#of samples, timesteps, #features(i.e. number of parallel time series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1988fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "x_train=x.reshape((x.shape[0], x.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8aa19df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 2, 20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee7c89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eed53d",
   "metadata": {},
   "source": [
    "# CNN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97d77517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gc\n",
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5339e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ForecastNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ForecastNet,self).__init__()\n",
    "        self.conv1d = nn.Conv1d(2,128,kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(128,64)\n",
    "        self.fc2 = nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,128)\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2eef3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_ForecastNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8332014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self,feature,target):\n",
    "        self.feature = feature\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        item = self.feature[idx]\n",
    "        label = self.target[idx]\n",
    "        \n",
    "        return item,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "85b7e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = myDataset(x_train,y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e7edebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "def Train():\n",
    "    \n",
    "    running_loss = .0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.to(torch.float32)\n",
    "        labels=labels.to(torch.float32)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs.float())\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "    train_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(train_loss.detach().numpy())\n",
    "    \n",
    "    print(f'train_loss {train_loss}')\n",
    "\n",
    "def Valid():\n",
    "    running_loss = .0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs.float())\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n",
    "            \n",
    "        valid_loss = running_loss/len(valid_loader)\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "        print(f'valid_loss {valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b105b4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Work Space\\anaconda3\\envs\\atd2022\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([1, 20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 89.11209106445312\n",
      "epochs 2/1000\n",
      "train_loss 89.10184478759766\n",
      "epochs 3/1000\n",
      "train_loss 89.09126281738281\n",
      "epochs 4/1000\n",
      "train_loss 89.0811767578125\n",
      "epochs 5/1000\n",
      "train_loss 89.0707778930664\n",
      "epochs 6/1000\n",
      "train_loss 89.06046295166016\n",
      "epochs 7/1000\n",
      "train_loss 89.050537109375\n",
      "epochs 8/1000\n",
      "train_loss 89.04032135009766\n",
      "epochs 9/1000\n",
      "train_loss 89.03024291992188\n",
      "epochs 10/1000\n",
      "train_loss 89.020263671875\n",
      "epochs 11/1000\n",
      "train_loss 89.01031494140625\n",
      "epochs 12/1000\n",
      "train_loss 89.00037384033203\n",
      "epochs 13/1000\n",
      "train_loss 88.99047088623047\n",
      "epochs 14/1000\n",
      "train_loss 88.98054504394531\n",
      "epochs 15/1000\n",
      "train_loss 88.9708023071289\n",
      "epochs 16/1000\n",
      "train_loss 88.96112823486328\n",
      "epochs 17/1000\n",
      "train_loss 88.95130920410156\n",
      "epochs 18/1000\n",
      "train_loss 88.94168090820312\n",
      "epochs 19/1000\n",
      "train_loss 88.93201446533203\n",
      "epochs 20/1000\n",
      "train_loss 88.92237854003906\n",
      "epochs 21/1000\n",
      "train_loss 88.912841796875\n",
      "epochs 22/1000\n",
      "train_loss 88.90332794189453\n",
      "epochs 23/1000\n",
      "train_loss 88.89389038085938\n",
      "epochs 24/1000\n",
      "train_loss 88.8842544555664\n",
      "epochs 25/1000\n",
      "train_loss 88.87500762939453\n",
      "epochs 26/1000\n",
      "train_loss 88.86573028564453\n",
      "epochs 27/1000\n",
      "train_loss 88.85626983642578\n",
      "epochs 28/1000\n",
      "train_loss 88.84701538085938\n",
      "epochs 29/1000\n",
      "train_loss 88.83784484863281\n",
      "epochs 30/1000\n",
      "train_loss 88.82861328125\n",
      "epochs 31/1000\n",
      "train_loss 88.81953430175781\n",
      "epochs 32/1000\n",
      "train_loss 88.8104019165039\n",
      "epochs 33/1000\n",
      "train_loss 88.80133056640625\n",
      "epochs 34/1000\n",
      "train_loss 88.79237365722656\n",
      "epochs 35/1000\n",
      "train_loss 88.78328704833984\n",
      "epochs 36/1000\n",
      "train_loss 88.77436065673828\n",
      "epochs 37/1000\n",
      "train_loss 88.76544952392578\n",
      "epochs 38/1000\n",
      "train_loss 88.75662994384766\n",
      "epochs 39/1000\n",
      "train_loss 88.74778747558594\n",
      "epochs 40/1000\n",
      "train_loss 88.7389144897461\n",
      "epochs 41/1000\n",
      "train_loss 88.73019409179688\n",
      "epochs 42/1000\n",
      "train_loss 88.7215576171875\n",
      "epochs 43/1000\n",
      "train_loss 88.71280670166016\n",
      "epochs 44/1000\n",
      "train_loss 88.70426940917969\n",
      "epochs 45/1000\n",
      "train_loss 88.69557189941406\n",
      "epochs 46/1000\n",
      "train_loss 88.68705749511719\n",
      "epochs 47/1000\n",
      "train_loss 88.67864227294922\n",
      "epochs 48/1000\n",
      "train_loss 88.67005920410156\n",
      "epochs 49/1000\n",
      "train_loss 88.66168975830078\n",
      "epochs 50/1000\n",
      "train_loss 88.65328216552734\n",
      "epochs 51/1000\n",
      "train_loss 88.64498901367188\n",
      "epochs 52/1000\n",
      "train_loss 88.63644409179688\n",
      "epochs 53/1000\n",
      "train_loss 88.62813568115234\n",
      "epochs 54/1000\n",
      "train_loss 88.6198959350586\n",
      "epochs 55/1000\n",
      "train_loss 88.6116943359375\n",
      "epochs 56/1000\n",
      "train_loss 88.60321044921875\n",
      "epochs 57/1000\n",
      "train_loss 88.5951156616211\n",
      "epochs 58/1000\n",
      "train_loss 88.58685302734375\n",
      "epochs 59/1000\n",
      "train_loss 88.57881927490234\n",
      "epochs 60/1000\n",
      "train_loss 88.5705795288086\n",
      "epochs 61/1000\n",
      "train_loss 88.56260681152344\n",
      "epochs 62/1000\n",
      "train_loss 88.55450439453125\n",
      "epochs 63/1000\n",
      "train_loss 88.54650115966797\n",
      "epochs 64/1000\n",
      "train_loss 88.53860473632812\n",
      "epochs 65/1000\n",
      "train_loss 88.5306167602539\n",
      "epochs 66/1000\n",
      "train_loss 88.52277374267578\n",
      "epochs 67/1000\n",
      "train_loss 88.51485443115234\n",
      "epochs 68/1000\n",
      "train_loss 88.5071029663086\n",
      "epochs 69/1000\n",
      "train_loss 88.49917602539062\n",
      "epochs 70/1000\n",
      "train_loss 88.49137115478516\n",
      "epochs 71/1000\n",
      "train_loss 88.48369598388672\n",
      "epochs 72/1000\n",
      "train_loss 88.4758529663086\n",
      "epochs 73/1000\n",
      "train_loss 88.46829223632812\n",
      "epochs 74/1000\n",
      "train_loss 88.4605712890625\n",
      "epochs 75/1000\n",
      "train_loss 88.4530029296875\n",
      "epochs 76/1000\n",
      "train_loss 88.4453125\n",
      "epochs 77/1000\n",
      "train_loss 88.43788146972656\n",
      "epochs 78/1000\n",
      "train_loss 88.4301528930664\n",
      "epochs 79/1000\n",
      "train_loss 88.42269897460938\n",
      "epochs 80/1000\n",
      "train_loss 88.41519165039062\n",
      "epochs 81/1000\n",
      "train_loss 88.40766906738281\n",
      "epochs 82/1000\n",
      "train_loss 88.40030670166016\n",
      "epochs 83/1000\n",
      "train_loss 88.39288330078125\n",
      "epochs 84/1000\n",
      "train_loss 88.38554382324219\n",
      "epochs 85/1000\n",
      "train_loss 88.378173828125\n",
      "epochs 86/1000\n",
      "train_loss 88.37100219726562\n",
      "epochs 87/1000\n",
      "train_loss 88.363525390625\n",
      "epochs 88/1000\n",
      "train_loss 88.35638427734375\n",
      "epochs 89/1000\n",
      "train_loss 88.34916687011719\n",
      "epochs 90/1000\n",
      "train_loss 88.34196472167969\n",
      "epochs 91/1000\n",
      "train_loss 88.33477020263672\n",
      "epochs 92/1000\n",
      "train_loss 88.3276596069336\n",
      "epochs 93/1000\n",
      "train_loss 88.32060241699219\n",
      "epochs 94/1000\n",
      "train_loss 88.3133773803711\n",
      "epochs 95/1000\n",
      "train_loss 88.30651092529297\n",
      "epochs 96/1000\n",
      "train_loss 88.29945373535156\n",
      "epochs 97/1000\n",
      "train_loss 88.29258728027344\n",
      "epochs 98/1000\n",
      "train_loss 88.2855224609375\n",
      "epochs 99/1000\n",
      "train_loss 88.27857971191406\n",
      "epochs 100/1000\n",
      "train_loss 88.27156829833984\n",
      "epochs 101/1000\n",
      "train_loss 88.26470184326172\n",
      "epochs 102/1000\n",
      "train_loss 88.2577133178711\n",
      "epochs 103/1000\n",
      "train_loss 88.25090026855469\n",
      "epochs 104/1000\n",
      "train_loss 88.24398803710938\n",
      "epochs 105/1000\n",
      "train_loss 88.23714447021484\n",
      "epochs 106/1000\n",
      "train_loss 88.23048400878906\n",
      "epochs 107/1000\n",
      "train_loss 88.22355651855469\n",
      "epochs 108/1000\n",
      "train_loss 88.21674346923828\n",
      "epochs 109/1000\n",
      "train_loss 88.2100601196289\n",
      "epochs 110/1000\n",
      "train_loss 88.203369140625\n",
      "epochs 111/1000\n",
      "train_loss 88.19657897949219\n",
      "epochs 112/1000\n",
      "train_loss 88.18995666503906\n",
      "epochs 113/1000\n",
      "train_loss 88.18316650390625\n",
      "epochs 114/1000\n",
      "train_loss 88.17652130126953\n",
      "epochs 115/1000\n",
      "train_loss 88.16991424560547\n",
      "epochs 116/1000\n",
      "train_loss 88.16320037841797\n",
      "epochs 117/1000\n",
      "train_loss 88.1566162109375\n",
      "epochs 118/1000\n",
      "train_loss 88.15010070800781\n",
      "epochs 119/1000\n",
      "train_loss 88.14344024658203\n",
      "epochs 120/1000\n",
      "train_loss 88.13700866699219\n",
      "epochs 121/1000\n",
      "train_loss 88.13050079345703\n",
      "epochs 122/1000\n",
      "train_loss 88.12397003173828\n",
      "epochs 123/1000\n",
      "train_loss 88.11753845214844\n",
      "epochs 124/1000\n",
      "train_loss 88.11117553710938\n",
      "epochs 125/1000\n",
      "train_loss 88.10469818115234\n",
      "epochs 126/1000\n",
      "train_loss 88.09829711914062\n",
      "epochs 127/1000\n",
      "train_loss 88.0920639038086\n",
      "epochs 128/1000\n",
      "train_loss 88.08570098876953\n",
      "epochs 129/1000\n",
      "train_loss 88.079345703125\n",
      "epochs 130/1000\n",
      "train_loss 88.07308197021484\n",
      "epochs 131/1000\n",
      "train_loss 88.06687927246094\n",
      "epochs 132/1000\n",
      "train_loss 88.06062316894531\n",
      "epochs 133/1000\n",
      "train_loss 88.05448913574219\n",
      "epochs 134/1000\n",
      "train_loss 88.04832458496094\n",
      "epochs 135/1000\n",
      "train_loss 88.04215240478516\n",
      "epochs 136/1000\n",
      "train_loss 88.03616333007812\n",
      "epochs 137/1000\n",
      "train_loss 88.03003692626953\n",
      "epochs 138/1000\n",
      "train_loss 88.02404022216797\n",
      "epochs 139/1000\n",
      "train_loss 88.01806640625\n",
      "epochs 140/1000\n",
      "train_loss 88.01210021972656\n",
      "epochs 141/1000\n",
      "train_loss 88.00614929199219\n",
      "epochs 142/1000\n",
      "train_loss 88.0002670288086\n",
      "epochs 143/1000\n",
      "train_loss 87.99427795410156\n",
      "epochs 144/1000\n",
      "train_loss 87.98847198486328\n",
      "epochs 145/1000\n",
      "train_loss 87.9825668334961\n",
      "epochs 146/1000\n",
      "train_loss 87.97671508789062\n",
      "epochs 147/1000\n",
      "train_loss 87.97099304199219\n",
      "epochs 148/1000\n",
      "train_loss 87.96507263183594\n",
      "epochs 149/1000\n",
      "train_loss 87.9594497680664\n",
      "epochs 150/1000\n",
      "train_loss 87.95372009277344\n",
      "epochs 151/1000\n",
      "train_loss 87.94793701171875\n",
      "epochs 152/1000\n",
      "train_loss 87.94217681884766\n",
      "epochs 153/1000\n",
      "train_loss 87.93663787841797\n",
      "epochs 154/1000\n",
      "train_loss 87.93083190917969\n",
      "epochs 155/1000\n",
      "train_loss 87.92520141601562\n",
      "epochs 156/1000\n",
      "train_loss 87.91963195800781\n",
      "epochs 157/1000\n",
      "train_loss 87.91404724121094\n",
      "epochs 158/1000\n",
      "train_loss 87.90846252441406\n",
      "epochs 159/1000\n",
      "train_loss 87.90289306640625\n",
      "epochs 160/1000\n",
      "train_loss 87.89728546142578\n",
      "epochs 161/1000\n",
      "train_loss 87.89179992675781\n",
      "epochs 162/1000\n",
      "train_loss 87.88626098632812\n",
      "epochs 163/1000\n",
      "train_loss 87.88082885742188\n",
      "epochs 164/1000\n",
      "train_loss 87.87540435791016\n",
      "epochs 165/1000\n",
      "train_loss 87.86980438232422\n",
      "epochs 166/1000\n",
      "train_loss 87.86436462402344\n",
      "epochs 167/1000\n",
      "train_loss 87.85895538330078\n",
      "epochs 168/1000\n",
      "train_loss 87.85343170166016\n",
      "epochs 169/1000\n",
      "train_loss 87.84793853759766\n",
      "epochs 170/1000\n",
      "train_loss 87.84249114990234\n",
      "epochs 171/1000\n",
      "train_loss 87.8370132446289\n",
      "epochs 172/1000\n",
      "train_loss 87.83161163330078\n",
      "epochs 173/1000\n",
      "train_loss 87.82613372802734\n",
      "epochs 174/1000\n",
      "train_loss 87.82083892822266\n",
      "epochs 175/1000\n",
      "train_loss 87.81534576416016\n",
      "epochs 176/1000\n",
      "train_loss 87.80998992919922\n",
      "epochs 177/1000\n",
      "train_loss 87.80461120605469\n",
      "epochs 178/1000\n",
      "train_loss 87.79930114746094\n",
      "epochs 179/1000\n",
      "train_loss 87.7939224243164\n",
      "epochs 180/1000\n",
      "train_loss 87.78874206542969\n",
      "epochs 181/1000\n",
      "train_loss 87.78337097167969\n",
      "epochs 182/1000\n",
      "train_loss 87.7780990600586\n",
      "epochs 183/1000\n",
      "train_loss 87.77288055419922\n",
      "epochs 184/1000\n",
      "train_loss 87.76758575439453\n",
      "epochs 185/1000\n",
      "train_loss 87.76238250732422\n",
      "epochs 186/1000\n",
      "train_loss 87.75714874267578\n",
      "epochs 187/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 87.75202941894531\n",
      "epochs 188/1000\n",
      "train_loss 87.74685668945312\n",
      "epochs 189/1000\n",
      "train_loss 87.74173736572266\n",
      "epochs 190/1000\n",
      "train_loss 87.73660278320312\n",
      "epochs 191/1000\n",
      "train_loss 87.73138427734375\n",
      "epochs 192/1000\n",
      "train_loss 87.72643280029297\n",
      "epochs 193/1000\n",
      "train_loss 87.7212905883789\n",
      "epochs 194/1000\n",
      "train_loss 87.71623992919922\n",
      "epochs 195/1000\n",
      "train_loss 87.71111297607422\n",
      "epochs 196/1000\n",
      "train_loss 87.70604705810547\n",
      "epochs 197/1000\n",
      "train_loss 87.7010269165039\n",
      "epochs 198/1000\n",
      "train_loss 87.69593811035156\n",
      "epochs 199/1000\n",
      "train_loss 87.69097900390625\n",
      "epochs 200/1000\n",
      "train_loss 87.68598937988281\n",
      "epochs 201/1000\n",
      "train_loss 87.68102264404297\n",
      "epochs 202/1000\n",
      "train_loss 87.67601013183594\n",
      "epochs 203/1000\n",
      "train_loss 87.67105865478516\n",
      "epochs 204/1000\n",
      "train_loss 87.66614532470703\n",
      "epochs 205/1000\n",
      "train_loss 87.66119384765625\n",
      "epochs 206/1000\n",
      "train_loss 87.65631103515625\n",
      "epochs 207/1000\n",
      "train_loss 87.65145111083984\n",
      "epochs 208/1000\n",
      "train_loss 87.64656066894531\n",
      "epochs 209/1000\n",
      "train_loss 87.64167785644531\n",
      "epochs 210/1000\n",
      "train_loss 87.63688659667969\n",
      "epochs 211/1000\n",
      "train_loss 87.63201141357422\n",
      "epochs 212/1000\n",
      "train_loss 87.62721252441406\n",
      "epochs 213/1000\n",
      "train_loss 87.62239837646484\n",
      "epochs 214/1000\n",
      "train_loss 87.61761474609375\n",
      "epochs 215/1000\n",
      "train_loss 87.61277770996094\n",
      "epochs 216/1000\n",
      "train_loss 87.6079330444336\n",
      "epochs 217/1000\n",
      "train_loss 87.603271484375\n",
      "epochs 218/1000\n",
      "train_loss 87.59848022460938\n",
      "epochs 219/1000\n",
      "train_loss 87.59379577636719\n",
      "epochs 220/1000\n",
      "train_loss 87.58905792236328\n",
      "epochs 221/1000\n",
      "train_loss 87.58426666259766\n",
      "epochs 222/1000\n",
      "train_loss 87.57962799072266\n",
      "epochs 223/1000\n",
      "train_loss 87.57501983642578\n",
      "epochs 224/1000\n",
      "train_loss 87.57034301757812\n",
      "epochs 225/1000\n",
      "train_loss 87.56563568115234\n",
      "epochs 226/1000\n",
      "train_loss 87.56111907958984\n",
      "epochs 227/1000\n",
      "train_loss 87.5563735961914\n",
      "epochs 228/1000\n",
      "train_loss 87.55183410644531\n",
      "epochs 229/1000\n",
      "train_loss 87.5472412109375\n",
      "epochs 230/1000\n",
      "train_loss 87.54259490966797\n",
      "epochs 231/1000\n",
      "train_loss 87.53807067871094\n",
      "epochs 232/1000\n",
      "train_loss 87.53339385986328\n",
      "epochs 233/1000\n",
      "train_loss 87.52890014648438\n",
      "epochs 234/1000\n",
      "train_loss 87.52434539794922\n",
      "epochs 235/1000\n",
      "train_loss 87.51979064941406\n",
      "epochs 236/1000\n",
      "train_loss 87.51536560058594\n",
      "epochs 237/1000\n",
      "train_loss 87.5108871459961\n",
      "epochs 238/1000\n",
      "train_loss 87.5063247680664\n",
      "epochs 239/1000\n",
      "train_loss 87.50184631347656\n",
      "epochs 240/1000\n",
      "train_loss 87.4973373413086\n",
      "epochs 241/1000\n",
      "train_loss 87.49291229248047\n",
      "epochs 242/1000\n",
      "train_loss 87.48841857910156\n",
      "epochs 243/1000\n",
      "train_loss 87.48404693603516\n",
      "epochs 244/1000\n",
      "train_loss 87.47956848144531\n",
      "epochs 245/1000\n",
      "train_loss 87.47516632080078\n",
      "epochs 246/1000\n",
      "train_loss 87.4708023071289\n",
      "epochs 247/1000\n",
      "train_loss 87.46640014648438\n",
      "epochs 248/1000\n",
      "train_loss 87.46192932128906\n",
      "epochs 249/1000\n",
      "train_loss 87.45769500732422\n",
      "epochs 250/1000\n",
      "train_loss 87.45325469970703\n",
      "epochs 251/1000\n",
      "train_loss 87.44886016845703\n",
      "epochs 252/1000\n",
      "train_loss 87.44462585449219\n",
      "epochs 253/1000\n",
      "train_loss 87.44023132324219\n",
      "epochs 254/1000\n",
      "train_loss 87.43596649169922\n",
      "epochs 255/1000\n",
      "train_loss 87.43167114257812\n",
      "epochs 256/1000\n",
      "train_loss 87.42740631103516\n",
      "epochs 257/1000\n",
      "train_loss 87.42305755615234\n",
      "epochs 258/1000\n",
      "train_loss 87.41888427734375\n",
      "epochs 259/1000\n",
      "train_loss 87.41451263427734\n",
      "epochs 260/1000\n",
      "train_loss 87.41033935546875\n",
      "epochs 261/1000\n",
      "train_loss 87.4061279296875\n",
      "epochs 262/1000\n",
      "train_loss 87.4018783569336\n",
      "epochs 263/1000\n",
      "train_loss 87.39766693115234\n",
      "epochs 264/1000\n",
      "train_loss 87.39347839355469\n",
      "epochs 265/1000\n",
      "train_loss 87.38922119140625\n",
      "epochs 266/1000\n",
      "train_loss 87.38510131835938\n",
      "epochs 267/1000\n",
      "train_loss 87.380859375\n",
      "epochs 268/1000\n",
      "train_loss 87.37673950195312\n",
      "epochs 269/1000\n",
      "train_loss 87.37265014648438\n",
      "epochs 270/1000\n",
      "train_loss 87.3685531616211\n",
      "epochs 271/1000\n",
      "train_loss 87.36441040039062\n",
      "epochs 272/1000\n",
      "train_loss 87.36028289794922\n",
      "epochs 273/1000\n",
      "train_loss 87.3561782836914\n",
      "epochs 274/1000\n",
      "train_loss 87.35218048095703\n",
      "epochs 275/1000\n",
      "train_loss 87.34799194335938\n",
      "epochs 276/1000\n",
      "train_loss 87.3438491821289\n",
      "epochs 277/1000\n",
      "train_loss 87.33985900878906\n",
      "epochs 278/1000\n",
      "train_loss 87.33580780029297\n",
      "epochs 279/1000\n",
      "train_loss 87.33174896240234\n",
      "epochs 280/1000\n",
      "train_loss 87.32769775390625\n",
      "epochs 281/1000\n",
      "train_loss 87.32371520996094\n",
      "epochs 282/1000\n",
      "train_loss 87.31966400146484\n",
      "epochs 283/1000\n",
      "train_loss 87.31560516357422\n",
      "epochs 284/1000\n",
      "train_loss 87.31178283691406\n",
      "epochs 285/1000\n",
      "train_loss 87.3077392578125\n",
      "epochs 286/1000\n",
      "train_loss 87.30376434326172\n",
      "epochs 287/1000\n",
      "train_loss 87.29985809326172\n",
      "epochs 288/1000\n",
      "train_loss 87.29584503173828\n",
      "epochs 289/1000\n",
      "train_loss 87.2919692993164\n",
      "epochs 290/1000\n",
      "train_loss 87.28801727294922\n",
      "epochs 291/1000\n",
      "train_loss 87.28411102294922\n",
      "epochs 292/1000\n",
      "train_loss 87.28028106689453\n",
      "epochs 293/1000\n",
      "train_loss 87.27645111083984\n",
      "epochs 294/1000\n",
      "train_loss 87.27249145507812\n",
      "epochs 295/1000\n",
      "train_loss 87.26883697509766\n",
      "epochs 296/1000\n",
      "train_loss 87.26493835449219\n",
      "epochs 297/1000\n",
      "train_loss 87.26107025146484\n",
      "epochs 298/1000\n",
      "train_loss 87.25730895996094\n",
      "epochs 299/1000\n",
      "train_loss 87.25349426269531\n",
      "epochs 300/1000\n",
      "train_loss 87.24967193603516\n",
      "epochs 301/1000\n",
      "train_loss 87.24594116210938\n",
      "epochs 302/1000\n",
      "train_loss 87.24220275878906\n",
      "epochs 303/1000\n",
      "train_loss 87.23837280273438\n",
      "epochs 304/1000\n",
      "train_loss 87.23470306396484\n",
      "epochs 305/1000\n",
      "train_loss 87.23092651367188\n",
      "epochs 306/1000\n",
      "train_loss 87.22718048095703\n",
      "epochs 307/1000\n",
      "train_loss 87.22348022460938\n",
      "epochs 308/1000\n",
      "train_loss 87.2197494506836\n",
      "epochs 309/1000\n",
      "train_loss 87.216064453125\n",
      "epochs 310/1000\n",
      "train_loss 87.21233367919922\n",
      "epochs 311/1000\n",
      "train_loss 87.20867919921875\n",
      "epochs 312/1000\n",
      "train_loss 87.20502471923828\n",
      "epochs 313/1000\n",
      "train_loss 87.2012939453125\n",
      "epochs 314/1000\n",
      "train_loss 87.19775390625\n",
      "epochs 315/1000\n",
      "train_loss 87.1939926147461\n",
      "epochs 316/1000\n",
      "train_loss 87.19042205810547\n",
      "epochs 317/1000\n",
      "train_loss 87.18672180175781\n",
      "epochs 318/1000\n",
      "train_loss 87.18315124511719\n",
      "epochs 319/1000\n",
      "train_loss 87.179443359375\n",
      "epochs 320/1000\n",
      "train_loss 87.17597961425781\n",
      "epochs 321/1000\n",
      "train_loss 87.17231750488281\n",
      "epochs 322/1000\n",
      "train_loss 87.1686782836914\n",
      "epochs 323/1000\n",
      "train_loss 87.16510009765625\n",
      "epochs 324/1000\n",
      "train_loss 87.16144561767578\n",
      "epochs 325/1000\n",
      "train_loss 87.157958984375\n",
      "epochs 326/1000\n",
      "train_loss 87.15430450439453\n",
      "epochs 327/1000\n",
      "train_loss 87.15072631835938\n",
      "epochs 328/1000\n",
      "train_loss 87.14716339111328\n",
      "epochs 329/1000\n",
      "train_loss 87.14361572265625\n",
      "epochs 330/1000\n",
      "train_loss 87.14004516601562\n",
      "epochs 331/1000\n",
      "train_loss 87.13652801513672\n",
      "epochs 332/1000\n",
      "train_loss 87.13298034667969\n",
      "epochs 333/1000\n",
      "train_loss 87.12944793701172\n",
      "epochs 334/1000\n",
      "train_loss 87.12599182128906\n",
      "epochs 335/1000\n",
      "train_loss 87.12238311767578\n",
      "epochs 336/1000\n",
      "train_loss 87.11894989013672\n",
      "epochs 337/1000\n",
      "train_loss 87.11537170410156\n",
      "epochs 338/1000\n",
      "train_loss 87.1119613647461\n",
      "epochs 339/1000\n",
      "train_loss 87.10840606689453\n",
      "epochs 340/1000\n",
      "train_loss 87.10499572753906\n",
      "epochs 341/1000\n",
      "train_loss 87.10150909423828\n",
      "epochs 342/1000\n",
      "train_loss 87.09797668457031\n",
      "epochs 343/1000\n",
      "train_loss 87.09455108642578\n",
      "epochs 344/1000\n",
      "train_loss 87.09107971191406\n",
      "epochs 345/1000\n",
      "train_loss 87.0875244140625\n",
      "epochs 346/1000\n",
      "train_loss 87.08416748046875\n",
      "epochs 347/1000\n",
      "train_loss 87.0807876586914\n",
      "epochs 348/1000\n",
      "train_loss 87.07726287841797\n",
      "epochs 349/1000\n",
      "train_loss 87.07389831542969\n",
      "epochs 350/1000\n",
      "train_loss 87.07048034667969\n",
      "epochs 351/1000\n",
      "train_loss 87.06697845458984\n",
      "epochs 352/1000\n",
      "train_loss 87.06362915039062\n",
      "epochs 353/1000\n",
      "train_loss 87.06028747558594\n",
      "epochs 354/1000\n",
      "train_loss 87.05679321289062\n",
      "epochs 355/1000\n",
      "train_loss 87.05347442626953\n",
      "epochs 356/1000\n",
      "train_loss 87.05010986328125\n",
      "epochs 357/1000\n",
      "train_loss 87.04669952392578\n",
      "epochs 358/1000\n",
      "train_loss 87.04327392578125\n",
      "epochs 359/1000\n",
      "train_loss 87.04000854492188\n",
      "epochs 360/1000\n",
      "train_loss 87.03666687011719\n",
      "epochs 361/1000\n",
      "train_loss 87.03328704833984\n",
      "epochs 362/1000\n",
      "train_loss 87.02994537353516\n",
      "epochs 363/1000\n",
      "train_loss 87.026611328125\n",
      "epochs 364/1000\n",
      "train_loss 87.02324676513672\n",
      "epochs 365/1000\n",
      "train_loss 87.01995849609375\n",
      "epochs 366/1000\n",
      "train_loss 87.01653289794922\n",
      "epochs 367/1000\n",
      "train_loss 87.01321411132812\n",
      "epochs 368/1000\n",
      "train_loss 87.00991821289062\n",
      "epochs 369/1000\n",
      "train_loss 87.00653839111328\n",
      "epochs 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 87.0031967163086\n",
      "epochs 371/1000\n",
      "train_loss 86.9998550415039\n",
      "epochs 372/1000\n",
      "train_loss 86.99651336669922\n",
      "epochs 373/1000\n",
      "train_loss 86.99321746826172\n",
      "epochs 374/1000\n",
      "train_loss 86.98985290527344\n",
      "epochs 375/1000\n",
      "train_loss 86.986572265625\n",
      "epochs 376/1000\n",
      "train_loss 86.9832992553711\n",
      "epochs 377/1000\n",
      "train_loss 86.98009490966797\n",
      "epochs 378/1000\n",
      "train_loss 86.97673797607422\n",
      "epochs 379/1000\n",
      "train_loss 86.97345733642578\n",
      "epochs 380/1000\n",
      "train_loss 86.97023010253906\n",
      "epochs 381/1000\n",
      "train_loss 86.96698760986328\n",
      "epochs 382/1000\n",
      "train_loss 86.96363067626953\n",
      "epochs 383/1000\n",
      "train_loss 86.96055603027344\n",
      "epochs 384/1000\n",
      "train_loss 86.95716857910156\n",
      "epochs 385/1000\n",
      "train_loss 86.95397186279297\n",
      "epochs 386/1000\n",
      "train_loss 86.95075988769531\n",
      "epochs 387/1000\n",
      "train_loss 86.94745635986328\n",
      "epochs 388/1000\n",
      "train_loss 86.94432830810547\n",
      "epochs 389/1000\n",
      "train_loss 86.94110107421875\n",
      "epochs 390/1000\n",
      "train_loss 86.93771362304688\n",
      "epochs 391/1000\n",
      "train_loss 86.93453979492188\n",
      "epochs 392/1000\n",
      "train_loss 86.93130493164062\n",
      "epochs 393/1000\n",
      "train_loss 86.92801666259766\n",
      "epochs 394/1000\n",
      "train_loss 86.92479705810547\n",
      "epochs 395/1000\n",
      "train_loss 86.9215087890625\n",
      "epochs 396/1000\n",
      "train_loss 86.91835021972656\n",
      "epochs 397/1000\n",
      "train_loss 86.91512298583984\n",
      "epochs 398/1000\n",
      "train_loss 86.91193389892578\n",
      "epochs 399/1000\n",
      "train_loss 86.90860748291016\n",
      "epochs 400/1000\n",
      "train_loss 86.90544128417969\n",
      "epochs 401/1000\n",
      "train_loss 86.9022445678711\n",
      "epochs 402/1000\n",
      "train_loss 86.89893341064453\n",
      "epochs 403/1000\n",
      "train_loss 86.8957290649414\n",
      "epochs 404/1000\n",
      "train_loss 86.89241027832031\n",
      "epochs 405/1000\n",
      "train_loss 86.88928985595703\n",
      "epochs 406/1000\n",
      "train_loss 86.88602447509766\n",
      "epochs 407/1000\n",
      "train_loss 86.88288879394531\n",
      "epochs 408/1000\n",
      "train_loss 86.87954711914062\n",
      "epochs 409/1000\n",
      "train_loss 86.87635040283203\n",
      "epochs 410/1000\n",
      "train_loss 86.87324523925781\n",
      "epochs 411/1000\n",
      "train_loss 86.86990356445312\n",
      "epochs 412/1000\n",
      "train_loss 86.86677551269531\n",
      "epochs 413/1000\n",
      "train_loss 86.86357116699219\n",
      "epochs 414/1000\n",
      "train_loss 86.86038208007812\n",
      "epochs 415/1000\n",
      "train_loss 86.85722351074219\n",
      "epochs 416/1000\n",
      "train_loss 86.85407257080078\n",
      "epochs 417/1000\n",
      "train_loss 86.85096740722656\n",
      "epochs 418/1000\n",
      "train_loss 86.84770202636719\n",
      "epochs 419/1000\n",
      "train_loss 86.84471893310547\n",
      "epochs 420/1000\n",
      "train_loss 86.84141540527344\n",
      "epochs 421/1000\n",
      "train_loss 86.83847045898438\n",
      "epochs 422/1000\n",
      "train_loss 86.83517456054688\n",
      "epochs 423/1000\n",
      "train_loss 86.83212280273438\n",
      "epochs 424/1000\n",
      "train_loss 86.82894897460938\n",
      "epochs 425/1000\n",
      "train_loss 86.82588195800781\n",
      "epochs 426/1000\n",
      "train_loss 86.82275390625\n",
      "epochs 427/1000\n",
      "train_loss 86.81964111328125\n",
      "epochs 428/1000\n",
      "train_loss 86.81657409667969\n",
      "epochs 429/1000\n",
      "train_loss 86.81336212158203\n",
      "epochs 430/1000\n",
      "train_loss 86.81036376953125\n",
      "epochs 431/1000\n",
      "train_loss 86.80722045898438\n",
      "epochs 432/1000\n",
      "train_loss 86.80402374267578\n",
      "epochs 433/1000\n",
      "train_loss 86.8009033203125\n",
      "epochs 434/1000\n",
      "train_loss 86.7978286743164\n",
      "epochs 435/1000\n",
      "train_loss 86.79474639892578\n",
      "epochs 436/1000\n",
      "train_loss 86.79158782958984\n",
      "epochs 437/1000\n",
      "train_loss 86.78858947753906\n",
      "epochs 438/1000\n",
      "train_loss 86.78546905517578\n",
      "epochs 439/1000\n",
      "train_loss 86.7824478149414\n",
      "epochs 440/1000\n",
      "train_loss 86.77935791015625\n",
      "epochs 441/1000\n",
      "train_loss 86.77637481689453\n",
      "epochs 442/1000\n",
      "train_loss 86.7732925415039\n",
      "epochs 443/1000\n",
      "train_loss 86.77030181884766\n",
      "epochs 444/1000\n",
      "train_loss 86.767333984375\n",
      "epochs 445/1000\n",
      "train_loss 86.76421356201172\n",
      "epochs 446/1000\n",
      "train_loss 86.76124572753906\n",
      "epochs 447/1000\n",
      "train_loss 86.75817108154297\n",
      "epochs 448/1000\n",
      "train_loss 86.75523376464844\n",
      "epochs 449/1000\n",
      "train_loss 86.75216674804688\n",
      "epochs 450/1000\n",
      "train_loss 86.74910736083984\n",
      "epochs 451/1000\n",
      "train_loss 86.74624633789062\n",
      "epochs 452/1000\n",
      "train_loss 86.7432632446289\n",
      "epochs 453/1000\n",
      "train_loss 86.74028015136719\n",
      "epochs 454/1000\n",
      "train_loss 86.73722839355469\n",
      "epochs 455/1000\n",
      "train_loss 86.73432159423828\n",
      "epochs 456/1000\n",
      "train_loss 86.73116302490234\n",
      "epochs 457/1000\n",
      "train_loss 86.72834014892578\n",
      "epochs 458/1000\n",
      "train_loss 86.72527313232422\n",
      "epochs 459/1000\n",
      "train_loss 86.72234344482422\n",
      "epochs 460/1000\n",
      "train_loss 86.71943664550781\n",
      "epochs 461/1000\n",
      "train_loss 86.71639251708984\n",
      "epochs 462/1000\n",
      "train_loss 86.71343994140625\n",
      "epochs 463/1000\n",
      "train_loss 86.71053314208984\n",
      "epochs 464/1000\n",
      "train_loss 86.70753479003906\n",
      "epochs 465/1000\n",
      "train_loss 86.70460510253906\n",
      "epochs 466/1000\n",
      "train_loss 86.70171356201172\n",
      "epochs 467/1000\n",
      "train_loss 86.69869232177734\n",
      "epochs 468/1000\n",
      "train_loss 86.69584655761719\n",
      "epochs 469/1000\n",
      "train_loss 86.6928482055664\n",
      "epochs 470/1000\n",
      "train_loss 86.68989562988281\n",
      "epochs 471/1000\n",
      "train_loss 86.68705749511719\n",
      "epochs 472/1000\n",
      "train_loss 86.68415069580078\n",
      "epochs 473/1000\n",
      "train_loss 86.68111419677734\n",
      "epochs 474/1000\n",
      "train_loss 86.67826080322266\n",
      "epochs 475/1000\n",
      "train_loss 86.67527770996094\n",
      "epochs 476/1000\n",
      "train_loss 86.67242431640625\n",
      "epochs 477/1000\n",
      "train_loss 86.66947937011719\n",
      "epochs 478/1000\n",
      "train_loss 86.66661071777344\n",
      "epochs 479/1000\n",
      "train_loss 86.66366577148438\n",
      "epochs 480/1000\n",
      "train_loss 86.66089630126953\n",
      "epochs 481/1000\n",
      "train_loss 86.6579360961914\n",
      "epochs 482/1000\n",
      "train_loss 86.65514373779297\n",
      "epochs 483/1000\n",
      "train_loss 86.65211486816406\n",
      "epochs 484/1000\n",
      "train_loss 86.6493148803711\n",
      "epochs 485/1000\n",
      "train_loss 86.646484375\n",
      "epochs 486/1000\n",
      "train_loss 86.64361572265625\n",
      "epochs 487/1000\n",
      "train_loss 86.64076232910156\n",
      "epochs 488/1000\n",
      "train_loss 86.63793182373047\n",
      "epochs 489/1000\n",
      "train_loss 86.63510131835938\n",
      "epochs 490/1000\n",
      "train_loss 86.63226318359375\n",
      "epochs 491/1000\n",
      "train_loss 86.62940979003906\n",
      "epochs 492/1000\n",
      "train_loss 86.62666320800781\n",
      "epochs 493/1000\n",
      "train_loss 86.62384796142578\n",
      "epochs 494/1000\n",
      "train_loss 86.62103271484375\n",
      "epochs 495/1000\n",
      "train_loss 86.6181869506836\n",
      "epochs 496/1000\n",
      "train_loss 86.615478515625\n",
      "epochs 497/1000\n",
      "train_loss 86.61260223388672\n",
      "epochs 498/1000\n",
      "train_loss 86.60980224609375\n",
      "epochs 499/1000\n",
      "train_loss 86.60710906982422\n",
      "epochs 500/1000\n",
      "train_loss 86.60433959960938\n",
      "epochs 501/1000\n",
      "train_loss 86.60150909423828\n",
      "epochs 502/1000\n",
      "train_loss 86.59878540039062\n",
      "epochs 503/1000\n",
      "train_loss 86.59600830078125\n",
      "epochs 504/1000\n",
      "train_loss 86.5932388305664\n",
      "epochs 505/1000\n",
      "train_loss 86.59049224853516\n",
      "epochs 506/1000\n",
      "train_loss 86.58775329589844\n",
      "epochs 507/1000\n",
      "train_loss 86.5849380493164\n",
      "epochs 508/1000\n",
      "train_loss 86.5822982788086\n",
      "epochs 509/1000\n",
      "train_loss 86.57946014404297\n",
      "epochs 510/1000\n",
      "train_loss 86.57669830322266\n",
      "epochs 511/1000\n",
      "train_loss 86.57406616210938\n",
      "epochs 512/1000\n",
      "train_loss 86.57125854492188\n",
      "epochs 513/1000\n",
      "train_loss 86.56853485107422\n",
      "epochs 514/1000\n",
      "train_loss 86.56590270996094\n",
      "epochs 515/1000\n",
      "train_loss 86.56302642822266\n",
      "epochs 516/1000\n",
      "train_loss 86.56041717529297\n",
      "epochs 517/1000\n",
      "train_loss 86.55768585205078\n",
      "epochs 518/1000\n",
      "train_loss 86.55494689941406\n",
      "epochs 519/1000\n",
      "train_loss 86.55223846435547\n",
      "epochs 520/1000\n",
      "train_loss 86.5495376586914\n",
      "epochs 521/1000\n",
      "train_loss 86.5467529296875\n",
      "epochs 522/1000\n",
      "train_loss 86.54411315917969\n",
      "epochs 523/1000\n",
      "train_loss 86.54134368896484\n",
      "epochs 524/1000\n",
      "train_loss 86.5386962890625\n",
      "epochs 525/1000\n",
      "train_loss 86.53597259521484\n",
      "epochs 526/1000\n",
      "train_loss 86.53327941894531\n",
      "epochs 527/1000\n",
      "train_loss 86.53056335449219\n",
      "epochs 528/1000\n",
      "train_loss 86.52787017822266\n",
      "epochs 529/1000\n",
      "train_loss 86.52526092529297\n",
      "epochs 530/1000\n",
      "train_loss 86.52246856689453\n",
      "epochs 531/1000\n",
      "train_loss 86.51979064941406\n",
      "epochs 532/1000\n",
      "train_loss 86.51712799072266\n",
      "epochs 533/1000\n",
      "train_loss 86.51444244384766\n",
      "epochs 534/1000\n",
      "train_loss 86.51171875\n",
      "epochs 535/1000\n",
      "train_loss 86.50904846191406\n",
      "epochs 536/1000\n",
      "train_loss 86.50636291503906\n",
      "epochs 537/1000\n",
      "train_loss 86.5037612915039\n",
      "epochs 538/1000\n",
      "train_loss 86.50102996826172\n",
      "epochs 539/1000\n",
      "train_loss 86.49842071533203\n",
      "epochs 540/1000\n",
      "train_loss 86.49566650390625\n",
      "epochs 541/1000\n",
      "train_loss 86.49309539794922\n",
      "epochs 542/1000\n",
      "train_loss 86.4903793334961\n",
      "epochs 543/1000\n",
      "train_loss 86.48773193359375\n",
      "epochs 544/1000\n",
      "train_loss 86.4851303100586\n",
      "epochs 545/1000\n",
      "train_loss 86.48233032226562\n",
      "epochs 546/1000\n",
      "train_loss 86.47984313964844\n",
      "epochs 547/1000\n",
      "train_loss 86.47710418701172\n",
      "epochs 548/1000\n",
      "train_loss 86.47456359863281\n",
      "epochs 549/1000\n",
      "train_loss 86.47183990478516\n",
      "epochs 550/1000\n",
      "train_loss 86.46919250488281\n",
      "epochs 551/1000\n",
      "train_loss 86.46658325195312\n",
      "epochs 552/1000\n",
      "train_loss 86.46390533447266\n",
      "epochs 553/1000\n",
      "train_loss 86.46131134033203\n",
      "epochs 554/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 86.45870971679688\n",
      "epochs 555/1000\n",
      "train_loss 86.45611572265625\n",
      "epochs 556/1000\n",
      "train_loss 86.45336151123047\n",
      "epochs 557/1000\n",
      "train_loss 86.45084381103516\n",
      "epochs 558/1000\n",
      "train_loss 86.4482192993164\n",
      "epochs 559/1000\n",
      "train_loss 86.44564056396484\n",
      "epochs 560/1000\n",
      "train_loss 86.44293975830078\n",
      "epochs 561/1000\n",
      "train_loss 86.44037628173828\n",
      "epochs 562/1000\n",
      "train_loss 86.43771362304688\n",
      "epochs 563/1000\n",
      "train_loss 86.4350814819336\n",
      "epochs 564/1000\n",
      "train_loss 86.43248748779297\n",
      "epochs 565/1000\n",
      "train_loss 86.42977142333984\n",
      "epochs 566/1000\n",
      "train_loss 86.42723846435547\n",
      "epochs 567/1000\n",
      "train_loss 86.4245376586914\n",
      "epochs 568/1000\n",
      "train_loss 86.42195892333984\n",
      "epochs 569/1000\n",
      "train_loss 86.41928100585938\n",
      "epochs 570/1000\n",
      "train_loss 86.41666412353516\n",
      "epochs 571/1000\n",
      "train_loss 86.41402435302734\n",
      "epochs 572/1000\n",
      "train_loss 86.4113998413086\n",
      "epochs 573/1000\n",
      "train_loss 86.40875244140625\n",
      "epochs 574/1000\n",
      "train_loss 86.4061050415039\n",
      "epochs 575/1000\n",
      "train_loss 86.40364837646484\n",
      "epochs 576/1000\n",
      "train_loss 86.40094757080078\n",
      "epochs 577/1000\n",
      "train_loss 86.39846801757812\n",
      "epochs 578/1000\n",
      "train_loss 86.39588165283203\n",
      "epochs 579/1000\n",
      "train_loss 86.39326477050781\n",
      "epochs 580/1000\n",
      "train_loss 86.39076232910156\n",
      "epochs 581/1000\n",
      "train_loss 86.38811492919922\n",
      "epochs 582/1000\n",
      "train_loss 86.38561248779297\n",
      "epochs 583/1000\n",
      "train_loss 86.38302612304688\n",
      "epochs 584/1000\n",
      "train_loss 86.38047790527344\n",
      "epochs 585/1000\n",
      "train_loss 86.3778305053711\n",
      "epochs 586/1000\n",
      "train_loss 86.37530517578125\n",
      "epochs 587/1000\n",
      "train_loss 86.37271881103516\n",
      "epochs 588/1000\n",
      "train_loss 86.37010192871094\n",
      "epochs 589/1000\n",
      "train_loss 86.36759185791016\n",
      "epochs 590/1000\n",
      "train_loss 86.3650131225586\n",
      "epochs 591/1000\n",
      "train_loss 86.3624038696289\n",
      "epochs 592/1000\n",
      "train_loss 86.35990905761719\n",
      "epochs 593/1000\n",
      "train_loss 86.35731506347656\n",
      "epochs 594/1000\n",
      "train_loss 86.35479736328125\n",
      "epochs 595/1000\n",
      "train_loss 86.35220336914062\n",
      "epochs 596/1000\n",
      "train_loss 86.34966278076172\n",
      "epochs 597/1000\n",
      "train_loss 86.34718322753906\n",
      "epochs 598/1000\n",
      "train_loss 86.34468841552734\n",
      "epochs 599/1000\n",
      "train_loss 86.34212493896484\n",
      "epochs 600/1000\n",
      "train_loss 86.33951568603516\n",
      "epochs 601/1000\n",
      "train_loss 86.33708953857422\n",
      "epochs 602/1000\n",
      "train_loss 86.33443450927734\n",
      "epochs 603/1000\n",
      "train_loss 86.33204650878906\n",
      "epochs 604/1000\n",
      "train_loss 86.32935333251953\n",
      "epochs 605/1000\n",
      "train_loss 86.32698059082031\n",
      "epochs 606/1000\n",
      "train_loss 86.32447814941406\n",
      "epochs 607/1000\n",
      "train_loss 86.32183837890625\n",
      "epochs 608/1000\n",
      "train_loss 86.3193588256836\n",
      "epochs 609/1000\n",
      "train_loss 86.31696319580078\n",
      "epochs 610/1000\n",
      "train_loss 86.31436920166016\n",
      "epochs 611/1000\n",
      "train_loss 86.31194305419922\n",
      "epochs 612/1000\n",
      "train_loss 86.30941772460938\n",
      "epochs 613/1000\n",
      "train_loss 86.30687713623047\n",
      "epochs 614/1000\n",
      "train_loss 86.30436706542969\n",
      "epochs 615/1000\n",
      "train_loss 86.30191802978516\n",
      "epochs 616/1000\n",
      "train_loss 86.29937744140625\n",
      "epochs 617/1000\n",
      "train_loss 86.29693603515625\n",
      "epochs 618/1000\n",
      "train_loss 86.29438781738281\n",
      "epochs 619/1000\n",
      "train_loss 86.29192352294922\n",
      "epochs 620/1000\n",
      "train_loss 86.28945922851562\n",
      "epochs 621/1000\n",
      "train_loss 86.28702545166016\n",
      "epochs 622/1000\n",
      "train_loss 86.2845230102539\n",
      "epochs 623/1000\n",
      "train_loss 86.28201293945312\n",
      "epochs 624/1000\n",
      "train_loss 86.27957153320312\n",
      "epochs 625/1000\n",
      "train_loss 86.27711486816406\n",
      "epochs 626/1000\n",
      "train_loss 86.27469635009766\n",
      "epochs 627/1000\n",
      "train_loss 86.2722396850586\n",
      "epochs 628/1000\n",
      "train_loss 86.2696533203125\n",
      "epochs 629/1000\n",
      "train_loss 86.26727294921875\n",
      "epochs 630/1000\n",
      "train_loss 86.26485443115234\n",
      "epochs 631/1000\n",
      "train_loss 86.2623519897461\n",
      "epochs 632/1000\n",
      "train_loss 86.25991821289062\n",
      "epochs 633/1000\n",
      "train_loss 86.25747680664062\n",
      "epochs 634/1000\n",
      "train_loss 86.25505065917969\n",
      "epochs 635/1000\n",
      "train_loss 86.25255584716797\n",
      "epochs 636/1000\n",
      "train_loss 86.25009155273438\n",
      "epochs 637/1000\n",
      "train_loss 86.24771118164062\n",
      "epochs 638/1000\n",
      "train_loss 86.24524688720703\n",
      "epochs 639/1000\n",
      "train_loss 86.24278259277344\n",
      "epochs 640/1000\n",
      "train_loss 86.24034118652344\n",
      "epochs 641/1000\n",
      "train_loss 86.23792266845703\n",
      "epochs 642/1000\n",
      "train_loss 86.23540496826172\n",
      "epochs 643/1000\n",
      "train_loss 86.23314666748047\n",
      "epochs 644/1000\n",
      "train_loss 86.23069763183594\n",
      "epochs 645/1000\n",
      "train_loss 86.2282943725586\n",
      "epochs 646/1000\n",
      "train_loss 86.22589111328125\n",
      "epochs 647/1000\n",
      "train_loss 86.2234115600586\n",
      "epochs 648/1000\n",
      "train_loss 86.22105407714844\n",
      "epochs 649/1000\n",
      "train_loss 86.21855926513672\n",
      "epochs 650/1000\n",
      "train_loss 86.2161636352539\n",
      "epochs 651/1000\n",
      "train_loss 86.21366119384766\n",
      "epochs 652/1000\n",
      "train_loss 86.21121978759766\n",
      "epochs 653/1000\n",
      "train_loss 86.20880126953125\n",
      "epochs 654/1000\n",
      "train_loss 86.20635986328125\n",
      "epochs 655/1000\n",
      "train_loss 86.20384979248047\n",
      "epochs 656/1000\n",
      "train_loss 86.20150756835938\n",
      "epochs 657/1000\n",
      "train_loss 86.19902801513672\n",
      "epochs 658/1000\n",
      "train_loss 86.1966323852539\n",
      "epochs 659/1000\n",
      "train_loss 86.1941146850586\n",
      "epochs 660/1000\n",
      "train_loss 86.19172668457031\n",
      "epochs 661/1000\n",
      "train_loss 86.18931579589844\n",
      "epochs 662/1000\n",
      "train_loss 86.18682098388672\n",
      "epochs 663/1000\n",
      "train_loss 86.18450164794922\n",
      "epochs 664/1000\n",
      "train_loss 86.18208312988281\n",
      "epochs 665/1000\n",
      "train_loss 86.17951965332031\n",
      "epochs 666/1000\n",
      "train_loss 86.17732238769531\n",
      "epochs 667/1000\n",
      "train_loss 86.17481231689453\n",
      "epochs 668/1000\n",
      "train_loss 86.17245483398438\n",
      "epochs 669/1000\n",
      "train_loss 86.17005920410156\n",
      "epochs 670/1000\n",
      "train_loss 86.16765594482422\n",
      "epochs 671/1000\n",
      "train_loss 86.16520690917969\n",
      "epochs 672/1000\n",
      "train_loss 86.1628189086914\n",
      "epochs 673/1000\n",
      "train_loss 86.1603775024414\n",
      "epochs 674/1000\n",
      "train_loss 86.15801239013672\n",
      "epochs 675/1000\n",
      "train_loss 86.1556625366211\n",
      "epochs 676/1000\n",
      "train_loss 86.15321350097656\n",
      "epochs 677/1000\n",
      "train_loss 86.15087890625\n",
      "epochs 678/1000\n",
      "train_loss 86.14844512939453\n",
      "epochs 679/1000\n",
      "train_loss 86.14593505859375\n",
      "epochs 680/1000\n",
      "train_loss 86.1436996459961\n",
      "epochs 681/1000\n",
      "train_loss 86.14122009277344\n",
      "epochs 682/1000\n",
      "train_loss 86.13877868652344\n",
      "epochs 683/1000\n",
      "train_loss 86.13645935058594\n",
      "epochs 684/1000\n",
      "train_loss 86.13407135009766\n",
      "epochs 685/1000\n",
      "train_loss 86.13162994384766\n",
      "epochs 686/1000\n",
      "train_loss 86.12924194335938\n",
      "epochs 687/1000\n",
      "train_loss 86.12689208984375\n",
      "epochs 688/1000\n",
      "train_loss 86.12455749511719\n",
      "epochs 689/1000\n",
      "train_loss 86.12213134765625\n",
      "epochs 690/1000\n",
      "train_loss 86.1197738647461\n",
      "epochs 691/1000\n",
      "train_loss 86.11740112304688\n",
      "epochs 692/1000\n",
      "train_loss 86.11505126953125\n",
      "epochs 693/1000\n",
      "train_loss 86.1126480102539\n",
      "epochs 694/1000\n",
      "train_loss 86.11029815673828\n",
      "epochs 695/1000\n",
      "train_loss 86.10791778564453\n",
      "epochs 696/1000\n",
      "train_loss 86.10554504394531\n",
      "epochs 697/1000\n",
      "train_loss 86.10319519042969\n",
      "epochs 698/1000\n",
      "train_loss 86.10088348388672\n",
      "epochs 699/1000\n",
      "train_loss 86.09848022460938\n",
      "epochs 700/1000\n",
      "train_loss 86.09609985351562\n",
      "epochs 701/1000\n",
      "train_loss 86.09373474121094\n",
      "epochs 702/1000\n",
      "train_loss 86.09130096435547\n",
      "epochs 703/1000\n",
      "train_loss 86.08907318115234\n",
      "epochs 704/1000\n",
      "train_loss 86.0866470336914\n",
      "epochs 705/1000\n",
      "train_loss 86.08434295654297\n",
      "epochs 706/1000\n",
      "train_loss 86.08193969726562\n",
      "epochs 707/1000\n",
      "train_loss 86.07969665527344\n",
      "epochs 708/1000\n",
      "train_loss 86.0772933959961\n",
      "epochs 709/1000\n",
      "train_loss 86.07498168945312\n",
      "epochs 710/1000\n",
      "train_loss 86.07258605957031\n",
      "epochs 711/1000\n",
      "train_loss 86.07025909423828\n",
      "epochs 712/1000\n",
      "train_loss 86.06793975830078\n",
      "epochs 713/1000\n",
      "train_loss 86.06571197509766\n",
      "epochs 714/1000\n",
      "train_loss 86.06331634521484\n",
      "epochs 715/1000\n",
      "train_loss 86.0610122680664\n",
      "epochs 716/1000\n",
      "train_loss 86.05860900878906\n",
      "epochs 717/1000\n",
      "train_loss 86.05640411376953\n",
      "epochs 718/1000\n",
      "train_loss 86.05404663085938\n",
      "epochs 719/1000\n",
      "train_loss 86.05171966552734\n",
      "epochs 720/1000\n",
      "train_loss 86.04937744140625\n",
      "epochs 721/1000\n",
      "train_loss 86.04718017578125\n",
      "epochs 722/1000\n",
      "train_loss 86.04474639892578\n",
      "epochs 723/1000\n",
      "train_loss 86.0425033569336\n",
      "epochs 724/1000\n",
      "train_loss 86.04022979736328\n",
      "epochs 725/1000\n",
      "train_loss 86.03791046142578\n",
      "epochs 726/1000\n",
      "train_loss 86.03559875488281\n",
      "epochs 727/1000\n",
      "train_loss 86.03329467773438\n",
      "epochs 728/1000\n",
      "train_loss 86.0309829711914\n",
      "epochs 729/1000\n",
      "train_loss 86.02877044677734\n",
      "epochs 730/1000\n",
      "train_loss 86.02635192871094\n",
      "epochs 731/1000\n",
      "train_loss 86.02413177490234\n",
      "epochs 732/1000\n",
      "train_loss 86.02189636230469\n",
      "epochs 733/1000\n",
      "train_loss 86.01954650878906\n",
      "epochs 734/1000\n",
      "train_loss 86.0173110961914\n",
      "epochs 735/1000\n",
      "train_loss 86.01494598388672\n",
      "epochs 736/1000\n",
      "train_loss 86.01277923583984\n",
      "epochs 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 86.01038360595703\n",
      "epochs 738/1000\n",
      "train_loss 86.0080795288086\n",
      "epochs 739/1000\n",
      "train_loss 86.00584411621094\n",
      "epochs 740/1000\n",
      "train_loss 86.00357818603516\n",
      "epochs 741/1000\n",
      "train_loss 86.00128173828125\n",
      "epochs 742/1000\n",
      "train_loss 85.99895477294922\n",
      "epochs 743/1000\n",
      "train_loss 85.99678039550781\n",
      "epochs 744/1000\n",
      "train_loss 85.99440002441406\n",
      "epochs 745/1000\n",
      "train_loss 85.99223327636719\n",
      "epochs 746/1000\n",
      "train_loss 85.98987579345703\n",
      "epochs 747/1000\n",
      "train_loss 85.98764038085938\n",
      "epochs 748/1000\n",
      "train_loss 85.9853286743164\n",
      "epochs 749/1000\n",
      "train_loss 85.98311614990234\n",
      "epochs 750/1000\n",
      "train_loss 85.98074340820312\n",
      "epochs 751/1000\n",
      "train_loss 85.97856140136719\n",
      "epochs 752/1000\n",
      "train_loss 85.97634887695312\n",
      "epochs 753/1000\n",
      "train_loss 85.97403717041016\n",
      "epochs 754/1000\n",
      "train_loss 85.97173309326172\n",
      "epochs 755/1000\n",
      "train_loss 85.969482421875\n",
      "epochs 756/1000\n",
      "train_loss 85.96717071533203\n",
      "epochs 757/1000\n",
      "train_loss 85.9649887084961\n",
      "epochs 758/1000\n",
      "train_loss 85.96269226074219\n",
      "epochs 759/1000\n",
      "train_loss 85.9603500366211\n",
      "epochs 760/1000\n",
      "train_loss 85.95825958251953\n",
      "epochs 761/1000\n",
      "train_loss 85.95588684082031\n",
      "epochs 762/1000\n",
      "train_loss 85.9537124633789\n",
      "epochs 763/1000\n",
      "train_loss 85.95138549804688\n",
      "epochs 764/1000\n",
      "train_loss 85.94921875\n",
      "epochs 765/1000\n",
      "train_loss 85.94688415527344\n",
      "epochs 766/1000\n",
      "train_loss 85.94467163085938\n",
      "epochs 767/1000\n",
      "train_loss 85.94248962402344\n",
      "epochs 768/1000\n",
      "train_loss 85.94013214111328\n",
      "epochs 769/1000\n",
      "train_loss 85.93795013427734\n",
      "epochs 770/1000\n",
      "train_loss 85.93573760986328\n",
      "epochs 771/1000\n",
      "train_loss 85.93351745605469\n",
      "epochs 772/1000\n",
      "train_loss 85.93125915527344\n",
      "epochs 773/1000\n",
      "train_loss 85.9290542602539\n",
      "epochs 774/1000\n",
      "train_loss 85.9267349243164\n",
      "epochs 775/1000\n",
      "train_loss 85.92469024658203\n",
      "epochs 776/1000\n",
      "train_loss 85.92234802246094\n",
      "epochs 777/1000\n",
      "train_loss 85.92028045654297\n",
      "epochs 778/1000\n",
      "train_loss 85.91802215576172\n",
      "epochs 779/1000\n",
      "train_loss 85.91577911376953\n",
      "epochs 780/1000\n",
      "train_loss 85.91358947753906\n",
      "epochs 781/1000\n",
      "train_loss 85.911376953125\n",
      "epochs 782/1000\n",
      "train_loss 85.90918731689453\n",
      "epochs 783/1000\n",
      "train_loss 85.90699005126953\n",
      "epochs 784/1000\n",
      "train_loss 85.90479278564453\n",
      "epochs 785/1000\n",
      "train_loss 85.90267944335938\n",
      "epochs 786/1000\n",
      "train_loss 85.900390625\n",
      "epochs 787/1000\n",
      "train_loss 85.89826965332031\n",
      "epochs 788/1000\n",
      "train_loss 85.8961181640625\n",
      "epochs 789/1000\n",
      "train_loss 85.89391326904297\n",
      "epochs 790/1000\n",
      "train_loss 85.89173126220703\n",
      "epochs 791/1000\n",
      "train_loss 85.88958740234375\n",
      "epochs 792/1000\n",
      "train_loss 85.88732147216797\n",
      "epochs 793/1000\n",
      "train_loss 85.88512420654297\n",
      "epochs 794/1000\n",
      "train_loss 85.88301086425781\n",
      "epochs 795/1000\n",
      "train_loss 85.88087463378906\n",
      "epochs 796/1000\n",
      "train_loss 85.8785400390625\n",
      "epochs 797/1000\n",
      "train_loss 85.87654113769531\n",
      "epochs 798/1000\n",
      "train_loss 85.87428283691406\n",
      "epochs 799/1000\n",
      "train_loss 85.87210083007812\n",
      "epochs 800/1000\n",
      "train_loss 85.8698959350586\n",
      "epochs 801/1000\n",
      "train_loss 85.86785888671875\n",
      "epochs 802/1000\n",
      "train_loss 85.86551666259766\n",
      "epochs 803/1000\n",
      "train_loss 85.86347961425781\n",
      "epochs 804/1000\n",
      "train_loss 85.86124420166016\n",
      "epochs 805/1000\n",
      "train_loss 85.8591079711914\n",
      "epochs 806/1000\n",
      "train_loss 85.85692596435547\n",
      "epochs 807/1000\n",
      "train_loss 85.85475158691406\n",
      "epochs 808/1000\n",
      "train_loss 85.85256958007812\n",
      "epochs 809/1000\n",
      "train_loss 85.85045623779297\n",
      "epochs 810/1000\n",
      "train_loss 85.84823608398438\n",
      "epochs 811/1000\n",
      "train_loss 85.84613037109375\n",
      "epochs 812/1000\n",
      "train_loss 85.84393310546875\n",
      "epochs 813/1000\n",
      "train_loss 85.84180450439453\n",
      "epochs 814/1000\n",
      "train_loss 85.83966064453125\n",
      "epochs 815/1000\n",
      "train_loss 85.83748626708984\n",
      "epochs 816/1000\n",
      "train_loss 85.83531951904297\n",
      "epochs 817/1000\n",
      "train_loss 85.83320617675781\n",
      "epochs 818/1000\n",
      "train_loss 85.83110809326172\n",
      "epochs 819/1000\n",
      "train_loss 85.82890319824219\n",
      "epochs 820/1000\n",
      "train_loss 85.82671356201172\n",
      "epochs 821/1000\n",
      "train_loss 85.82463836669922\n",
      "epochs 822/1000\n",
      "train_loss 85.82255554199219\n",
      "epochs 823/1000\n",
      "train_loss 85.82028198242188\n",
      "epochs 824/1000\n",
      "train_loss 85.81816864013672\n",
      "epochs 825/1000\n",
      "train_loss 85.8160400390625\n",
      "epochs 826/1000\n",
      "train_loss 85.81382751464844\n",
      "epochs 827/1000\n",
      "train_loss 85.81169128417969\n",
      "epochs 828/1000\n",
      "train_loss 85.80960845947266\n",
      "epochs 829/1000\n",
      "train_loss 85.80756378173828\n",
      "epochs 830/1000\n",
      "train_loss 85.8053207397461\n",
      "epochs 831/1000\n",
      "train_loss 85.80326843261719\n",
      "epochs 832/1000\n",
      "train_loss 85.8010482788086\n",
      "epochs 833/1000\n",
      "train_loss 85.79898071289062\n",
      "epochs 834/1000\n",
      "train_loss 85.79682159423828\n",
      "epochs 835/1000\n",
      "train_loss 85.7946548461914\n",
      "epochs 836/1000\n",
      "train_loss 85.79264068603516\n",
      "epochs 837/1000\n",
      "train_loss 85.79039001464844\n",
      "epochs 838/1000\n",
      "train_loss 85.78844451904297\n",
      "epochs 839/1000\n",
      "train_loss 85.78617095947266\n",
      "epochs 840/1000\n",
      "train_loss 85.7840347290039\n",
      "epochs 841/1000\n",
      "train_loss 85.78191375732422\n",
      "epochs 842/1000\n",
      "train_loss 85.77991485595703\n",
      "epochs 843/1000\n",
      "train_loss 85.77767944335938\n",
      "epochs 844/1000\n",
      "train_loss 85.7756118774414\n",
      "epochs 845/1000\n",
      "train_loss 85.77354431152344\n",
      "epochs 846/1000\n",
      "train_loss 85.77128601074219\n",
      "epochs 847/1000\n",
      "train_loss 85.7692642211914\n",
      "epochs 848/1000\n",
      "train_loss 85.76704406738281\n",
      "epochs 849/1000\n",
      "train_loss 85.76507568359375\n",
      "epochs 850/1000\n",
      "train_loss 85.76284790039062\n",
      "epochs 851/1000\n",
      "train_loss 85.7608413696289\n",
      "epochs 852/1000\n",
      "train_loss 85.75861358642578\n",
      "epochs 853/1000\n",
      "train_loss 85.756591796875\n",
      "epochs 854/1000\n",
      "train_loss 85.75440216064453\n",
      "epochs 855/1000\n",
      "train_loss 85.75231170654297\n",
      "epochs 856/1000\n",
      "train_loss 85.75031280517578\n",
      "epochs 857/1000\n",
      "train_loss 85.74810028076172\n",
      "epochs 858/1000\n",
      "train_loss 85.74604034423828\n",
      "epochs 859/1000\n",
      "train_loss 85.7438735961914\n",
      "epochs 860/1000\n",
      "train_loss 85.7418212890625\n",
      "epochs 861/1000\n",
      "train_loss 85.73963928222656\n",
      "epochs 862/1000\n",
      "train_loss 85.73763275146484\n",
      "epochs 863/1000\n",
      "train_loss 85.73534393310547\n",
      "epochs 864/1000\n",
      "train_loss 85.73338317871094\n",
      "epochs 865/1000\n",
      "train_loss 85.73126983642578\n",
      "epochs 866/1000\n",
      "train_loss 85.72914123535156\n",
      "epochs 867/1000\n",
      "train_loss 85.72698974609375\n",
      "epochs 868/1000\n",
      "train_loss 85.72496795654297\n",
      "epochs 869/1000\n",
      "train_loss 85.72284698486328\n",
      "epochs 870/1000\n",
      "train_loss 85.7208251953125\n",
      "epochs 871/1000\n",
      "train_loss 85.7186050415039\n",
      "epochs 872/1000\n",
      "train_loss 85.7165756225586\n",
      "epochs 873/1000\n",
      "train_loss 85.71450805664062\n",
      "epochs 874/1000\n",
      "train_loss 85.71248626708984\n",
      "epochs 875/1000\n",
      "train_loss 85.71034240722656\n",
      "epochs 876/1000\n",
      "train_loss 85.70825958251953\n",
      "epochs 877/1000\n",
      "train_loss 85.70620727539062\n",
      "epochs 878/1000\n",
      "train_loss 85.7042236328125\n",
      "epochs 879/1000\n",
      "train_loss 85.70199584960938\n",
      "epochs 880/1000\n",
      "train_loss 85.7000503540039\n",
      "epochs 881/1000\n",
      "train_loss 85.69794464111328\n",
      "epochs 882/1000\n",
      "train_loss 85.69581604003906\n",
      "epochs 883/1000\n",
      "train_loss 85.69368743896484\n",
      "epochs 884/1000\n",
      "train_loss 85.69175720214844\n",
      "epochs 885/1000\n",
      "train_loss 85.68962097167969\n",
      "epochs 886/1000\n",
      "train_loss 85.68753814697266\n",
      "epochs 887/1000\n",
      "train_loss 85.68556213378906\n",
      "epochs 888/1000\n",
      "train_loss 85.6834716796875\n",
      "epochs 889/1000\n",
      "train_loss 85.68135070800781\n",
      "epochs 890/1000\n",
      "train_loss 85.67923736572266\n",
      "epochs 891/1000\n",
      "train_loss 85.67730712890625\n",
      "epochs 892/1000\n",
      "train_loss 85.67514038085938\n",
      "epochs 893/1000\n",
      "train_loss 85.67315673828125\n",
      "epochs 894/1000\n",
      "train_loss 85.6709976196289\n",
      "epochs 895/1000\n",
      "train_loss 85.66900634765625\n",
      "epochs 896/1000\n",
      "train_loss 85.6668930053711\n",
      "epochs 897/1000\n",
      "train_loss 85.66478729248047\n",
      "epochs 898/1000\n",
      "train_loss 85.6628189086914\n",
      "epochs 899/1000\n",
      "train_loss 85.66072845458984\n",
      "epochs 900/1000\n",
      "train_loss 85.65876007080078\n",
      "epochs 901/1000\n",
      "train_loss 85.65658569335938\n",
      "epochs 902/1000\n",
      "train_loss 85.6545639038086\n",
      "epochs 903/1000\n",
      "train_loss 85.65264892578125\n",
      "epochs 904/1000\n",
      "train_loss 85.65042877197266\n",
      "epochs 905/1000\n",
      "train_loss 85.64846801757812\n",
      "epochs 906/1000\n",
      "train_loss 85.64642333984375\n",
      "epochs 907/1000\n",
      "train_loss 85.6444320678711\n",
      "epochs 908/1000\n",
      "train_loss 85.64227294921875\n",
      "epochs 909/1000\n",
      "train_loss 85.64027404785156\n",
      "epochs 910/1000\n",
      "train_loss 85.63831329345703\n",
      "epochs 911/1000\n",
      "train_loss 85.63616943359375\n",
      "epochs 912/1000\n",
      "train_loss 85.63417053222656\n",
      "epochs 913/1000\n",
      "train_loss 85.63209533691406\n",
      "epochs 914/1000\n",
      "train_loss 85.63014221191406\n",
      "epochs 915/1000\n",
      "train_loss 85.62805938720703\n",
      "epochs 916/1000\n",
      "train_loss 85.62589263916016\n",
      "epochs 917/1000\n",
      "train_loss 85.62400817871094\n",
      "epochs 918/1000\n",
      "train_loss 85.6218490600586\n",
      "epochs 919/1000\n",
      "train_loss 85.6198501586914\n",
      "epochs 920/1000\n",
      "train_loss 85.61787414550781\n",
      "epochs 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 85.6157455444336\n",
      "epochs 922/1000\n",
      "train_loss 85.61373901367188\n",
      "epochs 923/1000\n",
      "train_loss 85.61170959472656\n",
      "epochs 924/1000\n",
      "train_loss 85.609619140625\n",
      "epochs 925/1000\n",
      "train_loss 85.60768127441406\n",
      "epochs 926/1000\n",
      "train_loss 85.60562133789062\n",
      "epochs 927/1000\n",
      "train_loss 85.60352325439453\n",
      "epochs 928/1000\n",
      "train_loss 85.60150909423828\n",
      "epochs 929/1000\n",
      "train_loss 85.59947967529297\n",
      "epochs 930/1000\n",
      "train_loss 85.59734344482422\n",
      "epochs 931/1000\n",
      "train_loss 85.59550476074219\n",
      "epochs 932/1000\n",
      "train_loss 85.59339904785156\n",
      "epochs 933/1000\n",
      "train_loss 85.59136962890625\n",
      "epochs 934/1000\n",
      "train_loss 85.58929443359375\n",
      "epochs 935/1000\n",
      "train_loss 85.58729553222656\n",
      "epochs 936/1000\n",
      "train_loss 85.58525848388672\n",
      "epochs 937/1000\n",
      "train_loss 85.58319854736328\n",
      "epochs 938/1000\n",
      "train_loss 85.5811767578125\n",
      "epochs 939/1000\n",
      "train_loss 85.57921600341797\n",
      "epochs 940/1000\n",
      "train_loss 85.57714080810547\n",
      "epochs 941/1000\n",
      "train_loss 85.5750732421875\n",
      "epochs 942/1000\n",
      "train_loss 85.5731201171875\n",
      "epochs 943/1000\n",
      "train_loss 85.571044921875\n",
      "epochs 944/1000\n",
      "train_loss 85.569091796875\n",
      "epochs 945/1000\n",
      "train_loss 85.56705474853516\n",
      "epochs 946/1000\n",
      "train_loss 85.56504821777344\n",
      "epochs 947/1000\n",
      "train_loss 85.56298828125\n",
      "epochs 948/1000\n",
      "train_loss 85.56095886230469\n",
      "epochs 949/1000\n",
      "train_loss 85.55894470214844\n",
      "epochs 950/1000\n",
      "train_loss 85.55696868896484\n",
      "epochs 951/1000\n",
      "train_loss 85.55479431152344\n",
      "epochs 952/1000\n",
      "train_loss 85.55292510986328\n",
      "epochs 953/1000\n",
      "train_loss 85.55083465576172\n",
      "epochs 954/1000\n",
      "train_loss 85.54885864257812\n",
      "epochs 955/1000\n",
      "train_loss 85.54679107666016\n",
      "epochs 956/1000\n",
      "train_loss 85.54481506347656\n",
      "epochs 957/1000\n",
      "train_loss 85.542724609375\n",
      "epochs 958/1000\n",
      "train_loss 85.5407943725586\n",
      "epochs 959/1000\n",
      "train_loss 85.5388412475586\n",
      "epochs 960/1000\n",
      "train_loss 85.53677368164062\n",
      "epochs 961/1000\n",
      "train_loss 85.5347900390625\n",
      "epochs 962/1000\n",
      "train_loss 85.53271484375\n",
      "epochs 963/1000\n",
      "train_loss 85.5307846069336\n",
      "epochs 964/1000\n",
      "train_loss 85.52870178222656\n",
      "epochs 965/1000\n",
      "train_loss 85.52672576904297\n",
      "epochs 966/1000\n",
      "train_loss 85.52462005615234\n",
      "epochs 967/1000\n",
      "train_loss 85.52265167236328\n",
      "epochs 968/1000\n",
      "train_loss 85.52062225341797\n",
      "epochs 969/1000\n",
      "train_loss 85.5185775756836\n",
      "epochs 970/1000\n",
      "train_loss 85.51648712158203\n",
      "epochs 971/1000\n",
      "train_loss 85.5145492553711\n",
      "epochs 972/1000\n",
      "train_loss 85.51251983642578\n",
      "epochs 973/1000\n",
      "train_loss 85.51049041748047\n",
      "epochs 974/1000\n",
      "train_loss 85.50849914550781\n",
      "epochs 975/1000\n",
      "train_loss 85.50638580322266\n",
      "epochs 976/1000\n",
      "train_loss 85.50439453125\n",
      "epochs 977/1000\n",
      "train_loss 85.50238037109375\n",
      "epochs 978/1000\n",
      "train_loss 85.50041961669922\n",
      "epochs 979/1000\n",
      "train_loss 85.49832153320312\n",
      "epochs 980/1000\n",
      "train_loss 85.49635314941406\n",
      "epochs 981/1000\n",
      "train_loss 85.49431610107422\n",
      "epochs 982/1000\n",
      "train_loss 85.49231719970703\n",
      "epochs 983/1000\n",
      "train_loss 85.4903793334961\n",
      "epochs 984/1000\n",
      "train_loss 85.48831939697266\n",
      "epochs 985/1000\n",
      "train_loss 85.48632049560547\n",
      "epochs 986/1000\n",
      "train_loss 85.484375\n",
      "epochs 987/1000\n",
      "train_loss 85.4822998046875\n",
      "epochs 988/1000\n",
      "train_loss 85.48033142089844\n",
      "epochs 989/1000\n",
      "train_loss 85.47836303710938\n",
      "epochs 990/1000\n",
      "train_loss 85.4764404296875\n",
      "epochs 991/1000\n",
      "train_loss 85.47428131103516\n",
      "epochs 992/1000\n",
      "train_loss 85.47235107421875\n",
      "epochs 993/1000\n",
      "train_loss 85.47039794921875\n",
      "epochs 994/1000\n",
      "train_loss 85.46833801269531\n",
      "epochs 995/1000\n",
      "train_loss 85.46633911132812\n",
      "epochs 996/1000\n",
      "train_loss 85.4644775390625\n",
      "epochs 997/1000\n",
      "train_loss 85.46244812011719\n",
      "epochs 998/1000\n",
      "train_loss 85.46040344238281\n",
      "epochs 999/1000\n",
      "train_loss 85.4584732055664\n",
      "epochs 1000/1000\n",
      "train_loss 85.4563980102539\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "    Train()\n",
    "    #Valid()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7c7c9ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2649c117130>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAEICAYAAABh6uw+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAArMElEQVR4nO3deZxcZZ3v8c+vqvc9SW9ZSQIBEkISSBsRAVEBIaCIDILDKMyoqKCio3OFO8t17kWFQdSXI4oRUEBBHZBlBFnGGYPI2oEE0gnZmyyd3rL0knR3evndP+p00kmqk+6uTupU6vt+vepVVafOU/V7Iuab5znPOcfcHREREUm+SLILEBERkRiFsoiISEgolEVEREJCoSwiIhISCmUREZGQUCiLiIiEhEJZREQkJBTKckwzs1oz22NmpQdsX2pmbmZTg/eTzOwRM2s2sxYze8vMrg0+mxrs237A48pBfvNPZvaZI903ETn2ZCS7AJGjYAPwCeDfAczsVCD3gH0eAJYBxwFdwKlA5QH7lLh7z5EtVUTSmUbKkg4eAD414P01wP0H7PMu4Bfuvsvde9z9DXf/w2gWYWYRM/snM3vHzBrN7H4zKw4+yzGzX5rZNjPbaWavmVlF8Nm1ZrbezNrMbIOZXT2adYlIeCiUJR28DBSZ2UwziwJXAr+Ms8+dZnaVmU05QnVcGzzeD0wHCoAfBZ9dAxQDk4FxwOeBDjPLB34IXOTuhcCZwNIjVJ+IJJlCWdJF/2j5fOBtYMsBn18B/Bn4Z2BDcMz5XQfs0xyMYvsfM4dZw9XA99x9vbu3AzcDV5lZBtBNLIxPcPded1/i7q1Buz5gtpnluvtWd68Z5u+KSIpQKEu6eAD4a2Ij1QOnrnH3He5+k7ufAlQQG40+ZmY2YLdSdy8Z8Fg5zBomAO8MeP8OsXUdFUF9zwC/NrM6M/s3M8t0913ERvafB7aa2ZNmdvIwf1dEUoRCWdKCu79DbMHXQuB3h9m3GfgusRAdO4pl1BFbSNZvCtADNLh7t7v/q7vPIjZFfQnBcXB3f8bdzwfGExvl/2wUaxKREFEoSzr5NPCBYPS5HzO7zcxmm1mGmRUCXwDWuvu2Ef5WRrB4q/+RCTwEfNXMpplZAfBt4Dfu3mNm7zezU4Nj3q3EprN7zazCzD4SHFvuAtqB3hHWJCIhp1CWtOHu69y9epCP84BHgZ3AemIj2o8csM/OA85T/vtD/NxPgI4Bj58D9xKbpn6e2Ki9E/hSsH8l8DCxQF4JLCa2GC0CfI3YKHs78D7g+iF2WURSjLl7smsQERERNFIWEREJDYWyiIhISCiURUREQkKhLCIiEhIpdUOK0tJSnzp1arLLEBFJKUuWLGl297IE2pdnZGTcDcxGg7lE9AHLe3p6PjN//vzGeDukVChPnTqV6urBzmgREZF4zOydw+81uIyMjLsrKytnlpWV7YhEIjplZ4T6+vqsqalpVn19/d0cfMoloH/xiIjI4c0uKytrVSAnJhKJeFlZWQuxGYf4+xzFekREJDVFFMijI/hzHDR7FcoiIiIhoVAWEREJCYWyiIiEXnNzc/TWW28d9gry973vfSc0NzdHh9vu8ssvn/rzn/98zHDbJeqwoWxm95pZo5ktH7BtrJk9Z2ZrgucxwfbzzWyJmb0VPH9gkO/8ppltCW4kv9TMFo5el0RE5Fizbdu26D333FN+4Paenp5Dtlu8ePHa0tLSlLmz2lBOifoF8CP2vzH8TcAf3f1WM7speP8NoBn4sLvXmdlsYjdtnzjI937f3b874spFROSo+4eHl01eXd+WN5rfeWJl4e7b/2rupkPt87WvfW3Spk2bsk8++eRZGRkZnp+f31teXt69YsWKvHXr1tWcd955x2/dujWrq6sr8vnPf77h61//ejPAxIkTT62url7Z2toaueiii2YsWLCgvbq6uqCiomLPM888s7agoOCwC9gef/zxwptuumlyb28vc+fO3X3//fe/k5ub69dff/3EZ555piQajfq5557bumjRos333nvvmO985zsTIpGIFxYW9lZXV68azp/FYUfK7v48sVvGDXQpcF/w+j7go8G+b7h7XbC9Bsgxs+zhFHQk/HFlAz/+09pklyEiIiN0xx13bJ48eXLX22+/veLWW2/d/Oabb+bffvvtW9atW1cD8Ktf/aq2pqZm5dKlS1f89Kc/raivrz9oynrjxo05X/7ylxvXrl1bU1xc3Hv//fcfdnp69+7d9rnPfW7ab37zm3WrV69e0dPTw+23317W0NAQfeqpp8asWbOmZvXq1Su+/e1vbwW49dZbxz/77LOrV61ateLpp58edvCM9OIhFe6+FcDdt5rZQVMKwOXAG+7eNch3fNHMPgVUA19z9x3xdjKz64DrAKZMmTKiYv+0qonfv1nH9eeeMKL2IiISc7gR7dEyZ86cXSeffPKe/ve33XZbxZNPPlkCUF9fn1lTU5NTWVm5a2CbiRMndp155pkdAKeddtru2traww4aly1bljNp0qSuOXPmdAFce+212+68887ym2++uTE7O7vvqquuOu7iiy9uufLKK1sAqqqq2q+++uqpl19++Y6rr746bq4dyhFZ6GVmpwC3AZ8bZJefAMcD84CtwB2DfZe7L3L3KnevKisb2VXiohGjt0+n2ImIHCvy8vL6+l///ve/L1y8eHFhdXX126tWrVoxc+bMjo6OjoPyLSsra28QRKNR7+npscP9jnv87MjMzGTp0qUrL7/88p2PPfZYybnnnjsD4MEHH9x4yy231G3atClr3rx5p8QbsR/KSEO5wczGAwTPe6/haWaTgEeBT7n7uniN3b3B3XvdvQ/4GbBghHUMScQMZbKISOoqLi7u3bVrV9zM2rlzZ7S4uLi3sLCw74033shZtmxZ/mj97rx58zq3bNmStXz58myA+++/f9zZZ5/d1tLSEtm+fXv0yiuvbLnrrrs2rVy5Mg+gpqYm+wMf+MCuH/zgB3VjxozpWb9+fdZwfm+k09dPANcAtwbPjwOYWQnwJHCzu/9lsMZmNr5/+hu4DFg+2L6jISNq9PT1HX5HEREJpcrKyt758+e3z5gx45Ts7Oy+srKy7v7PLr/88pZFixaVnXjiibOOP/74zrlz5+461HcNR15ent911121V1xxxfH9C72+/vWvNzU2NmZccsklJ3R1dRnALbfcsgngq1/96qTa2tpsd7ezzjqr9YwzzugYzu/ZYEPzvTuYPQScC5QCDcD/AR4DfgtMATYCV7j7djP7J+BmYM2Ar7jA3RvN7G7gLnevNrMHiE1dO1ALfG5ASA+qqqrKR3JDilv/8Db3vrCB1d+6aNhtRURSnZktcfeqkbZftmxZ7dy5c5tHs6Z0tmzZstK5c+dOjffZYUfK7v6JQT76YJx9bwFuGeR7PjPg9ScP97ujKRqB3sP840NERCTZUurWjSMVNS30EhGRg33yk5+c8tprrxUM3PaFL3yh4cYbb9yWjHrSIpQjkdgCu74+3/taRESGrK+vr8+OxTtFPfDAAxuP5u/19fUZMOgip7S49nXUYkGsKWwRkRFZ3tTUVBwEioxQX1+fNTU1FXOIxc1pNVLu7XMyh31ZchGR9NbT0/OZ+vr6u+vr62eTJoO5I6QPWN7T0/OZwXZIi1DO6J++1khZRGTY5s+f3wh8JNl1pIO0+BdPNAjlHi32EhGREEuLUI7YvoVeIiIiYZUWoRwdcExZREQkrNIilPcu9NIxZRERCbG0COXo3unrJBciIiJyCOkRykEvNVIWEZEwS4tQ1kIvERFJBWkRyhlRnRIlIiLhlxah3D9S1uprEREJs7QI5aiu6CUiIikgPUJZI2UREUkBaRHKEV08REREUkBahPLe85Q1fS0iIiGWHqGskbKIiKSAtApljZRFRCTMDhvKZnavmTWa2fIB28aa2XNmtiZ4HjPgs5vNbK2ZrTKzDw3ynYO2PxL23rqxV6EsIiLhNZSR8i+ACw/YdhPwR3efAfwxeI+ZzQKuAk4J2vzYzKJxvjNu+yNl73nKGimLiEiIHTaU3f15YPsBmy8F7gte3wd8dMD2X7t7l7tvANYCC+J87WDtj4i909e6IYWIiITYSI8pV7j7VoDguTzYPhHYNGC/zcG2obY/iJldZ2bVZlbd1NQ0omJ1QwoREUkFo73Qy+JsSygJ3X2Ru1e5e1VZWdmIvkM3pBARkVQw0lBuMLPxAMFzY7B9MzB5wH6TgLphtD8idEqUiIikgpGG8hPANcHra4DHB2y/ysyyzWwaMAN4dRjtjwgt9BIRkVQwlFOiHgJeAk4ys81m9mngVuB8M1sDnB+8x91rgN8CK4CngRvcvTf4nrvNrCr42rjtj5T+WzdqpCwiImGWcbgd3P0Tg3z0wUH2/xbwrTjbPzPg9bbB2h8JuiGFiIikgrS4oldEV/QSEZEUkBahrJGyiIikgvQIZa2+FhGRFJAWoazpaxERSQVpEcr7pq+TXIiIiMghpEcoR3SesoiIhF96hbKGyiIiEmJpEcr9Fw/p0UIvEREJsbQI5cxIrJvdvQplEREJr7QI5b0jZU1fi4hIiKVHKAfHlLs1fS0iIiGWFqFsZmRGjW6NlEVEJMTSIpQBMiIRTV+LiEiopU8oR00LvUREJNTSJpSzohFNX4uISKilTShnRI0ejZRFRCTE0ieUIxG6+zRSFhGR8EqbUM7KiGikLCIioZY2oZwR0SlRIiISbukTytGIVl+LiEioZSTS2MxuBD4LGPAzd/+Bmf0GOCnYpQTY6e7z4rStBdqAXqDH3asSqeVwMqNGj44pi4hIiI04lM1sNrFAXgDsAZ42syfd/coB+9wBtBzia97v7s0jrWE4MnVKlIiIhFwi09czgZfdfbe79wCLgcv6PzQzAz4OPJRYiaMjdkxZ09ciIhJeiYTycuAcMxtnZnnAQmDygM/PBhrcfc0g7R141syWmNl1g/2ImV1nZtVmVt3U1DTiYjOjusymiIiE24inr919pZndBjwHtAPLgJ4Bu3yCQ4+S3+vudWZWDjxnZm+7+/NxfmcRsAigqqpqxEPdjKjRo7tEiYhIiCW0+trd73H30939HGA7sAbAzDKAjwG/OUTbuuC5EXiU2LHpIyYzGmFPj0bKIiISXgmFcjDKxcymEAvh/pHxecDb7r55kHb5ZlbY/xq4gNh0+BGTqZGyiIiEXEKnRAGPmNk4oBu4wd13BNuv4oCpazObANzt7guBCuDR2FowMoAH3f3pBGs5JN26UUREwi6hUHb3swfZfm2cbXXEFoPh7uuBuYn89nBl6uIhIiIScmlzRa/MqC6zKSIi4ZY2oazV1yIiEnZpE8pafS0iImGXNqGcmxmls7s32WWIiIgMKm1COSczSk+fawW2iIiEVhqFcqyrnZrCFhGRkEqjUI4C0LFHU9giIhJOaRfKOq4sIiJhlXah3NWjUBYRkXBKn1DOiHW1Y4+OKYuISDilTSjnZgXT1xopi4hISKVNKOuYsoiIhF36hHJGfyhr+lpERMIpfUI5OE+5QyNlEREJqTQKZU1fi4hIuKVdKHcplEVEJKTSJpTzgtXXu3RFLxERCam0CuVoxGjr7E52KSIiInGlTSibGYU5GbR19iS7FBERkbjSJpQBCnMyaO3QSFlERMIpoVA2sxvNbLmZ1ZjZV4Jt3zSzLWa2NHgsHKTthWa2yszWmtlNidQxVIXZmRopi4hIaGWMtKGZzQY+CywA9gBPm9mTwcffd/fvHqJtFLgTOB/YDLxmZk+4+4qR1jMURbmavhYRkfBKZKQ8E3jZ3Xe7ew+wGLhsiG0XAGvdfb277wF+DVyaQC1DUpiTSasWeomISEglEsrLgXPMbJyZ5QELgcnBZ180szfN7F4zGxOn7URg04D3m4NtBzGz68ys2syqm5qaEigXinI0fS0iIuE14lB295XAbcBzwNPAMqAH+AlwPDAP2ArcEae5xfvKQX5nkbtXuXtVWVnZSMsFYtPXLVroJSIiIZXQQi93v8fdT3f3c4DtwBp3b3D3XnfvA35GbKr6QJvZN6oGmATUJVLLUIzLz6K9q0eX2hQRkVBKdPV1efA8BfgY8JCZjR+wy2XEprkP9Boww8ymmVkWcBXwRCK1DEVZYTYAze1dR/qnREREhm3Eq68Dj5jZOKAbuMHdd5jZA2Y2j9h0dC3wOQAzmwDc7e4L3b3HzL4IPANEgXvdvSbBWg6rtCAWyk1tXUwak3ekf05ERGRYEgpldz87zrZPDrJvHbHFYP3vnwKeSuT3h2vfSHnP0fxZERGRIUmrK3r1h3JTm6avRUQkfNIqlEsLsokYbG3pSHYpIiIiB0mrUM6MRhhfnMum7buTXYqIiMhB0iqUAY4bl8dGhbKIiIRQ2oXylLEKZRERCae0C+XJY/Nobt/Dri5dblNERMIl7UL5uHGx85M1WhYRkbBJu1CeUV4IwKr6tiRXIiIisr+0C+XpZflkZURYsbU12aWIiIjsJ+1COTMa4aSKQlbUKZRFRCRc0i6UAWaNL6KmrgX3uHeLFBERSYq0DOV5U0rYsbub9c27kl2KiIjIXmkZyu+eNhaAV9ZvT3IlIiIi+6RlKE8rzae0IJtXN2xLdikiIiJ7pWUomxnvnj6WVzZs13FlEREJjbQMZYCzTihla0snqxp0vrKIiIRD2obyB2eWYwbP1TQkuxQREREgjUO5vDCHeZNLeHaFQllERMIhbUMZ4IJZlby1pYW6nR3JLkVERCS9Q/nC2ZUAPLGsLsmViIiIJBjKZnajmS03sxoz+0qw7XYze9vM3jSzR82sZJC2tWb2lpktNbPqROoYqWml+cw/bgwPL9msVdgiIpJ0Iw5lM5sNfBZYAMwFLjGzGcBzwGx3nwOsBm4+xNe8393nuXvVSOtI1BXzJ7G2sZ2lm3YmqwQREREgsZHyTOBld9/t7j3AYuAyd382eA/wMjAp0SKPpIvnjCc3M8qDr2xMdikiIpLmEgnl5cA5ZjbOzPKAhcDkA/b5O+APg7R34FkzW2Jm1w32I2Z2nZlVm1l1U1NTAuXGV5iTyV/Nn8TjS+tobOsc9e8XEREZqhGHsruvBG4jNl39NLAM6B8hY2b/GLz/1SBf8V53Px24CLjBzM4Z5HcWuXuVu1eVlZWNtNxD+vRZ0+ju6+OBl945It8vIiIyFAkt9HL3e9z9dHc/B9gOrAEws2uAS4CrfZAVVO5eFzw3Ao8SOzadFFNL8zl/ZgUPvPwOu7p6Dt9ARETkCEh09XV58DwF+BjwkJldCHwD+Ii77x6kXb6ZFfa/Bi4gNh2eNNe//wR27u7m3hc2JLMMERFJY4mep/yIma0A/hO4wd13AD8CCoHngtOd7gIwswlm9lTQrgJ4wcyWAa8CT7r70wnWkpB5k0u4YFYFi55fz45de5JZioiIpClLpfNzq6qqvLr6yJ3SvLqhjQ/94Hk+e/Z0/vfCmUfsd0REjiYzW5LMU09l6NL6il4HOrGikMtPn8Qv/lLLuqb2ZJcjIiJpRqF8gG9ceDI5mRH++bHlusqXiIgcVQrlA5QVZvMPF57Mi+u28djSLckuR0RE0ohCOY6/XjCF06aU8M0nVrC1RXeQEhGRo0OhHEc0Ynzv4/Po7u3ja79dRl+fprFFROTIUygPYlppPv9yySxeXLeNn/15fbLLERGRNKBQPoQr3zWZi2ZX8m/PrOLFtc3JLkdERI5xCuVDMDNuv2Iu00vzueHB19m8I+4FykREREaFQvkwCrIzWPSpKnr6nM89sITde3RtbBEROTIUykMwrTSfH151Giu3tnLDr16nu7cv2SWJiMgxSKE8RO8/uZxvXXYq/7OqiW888qYuLCIiIqMuI9kFpJJPLJhCU1sX33tuNaUF2dx80cmYWbLLEhGRY4RCeZi+9IETaG7vYtHz64mY8Y0LT1Iwi4jIqFAoD5OZ8c0Pn0KfO3ctXkd3bx//dPFMBbOIiCRMoTwCkYjx/y6dTWY0wj0vbKC7t49vfvgUIhEFs4iIjJxCeYTMjH+5ZBaZ0QiLnl/Pjt3d3P5Xc8jJjCa7NBERSVEK5QSYGTdfdDJj87O49Q9vU7ezg0WfnM+4guxklyYiIilIp0QlyMz4/PuO58dXn87yLS187Ccvsq6pPdlliYhIClIoj5KFp47noevOoL2zh4/9+EWeX92U7JJERCTFKJRH0elTxvDo9e+loiiba37+Kj/4r9X06raPIiIyRAmFspndaGbLzazGzL4SbBtrZs+Z2ZrgecwgbS80s1VmttbMbkqkjjCZMi6Px254L5fNm8gP/msN1/78Vba1dyW7LBERSQEjDmUzmw18FlgAzAUuMbMZwE3AH919BvDH4P2BbaPAncBFwCzgE2Y2a6S1hE1eVgZ3fHwu3/nYqbyyYTsLf/hn/rxG09kiInJoiYyUZwIvu/tud+8BFgOXAZcC9wX73Ad8NE7bBcBad1/v7nuAXwftjhlmxicWTOF3XziTwpxMPnnPq3zziRo6u3uTXZqIiIRUIqG8HDjHzMaZWR6wEJgMVLj7VoDguTxO24nApgHvNwfbDmJm15lZtZlVNzWl3mhz9sRifv+ls7j2zKn84sVaLvn3F1i+pSXZZYmISAiNOJTdfSVwG/Ac8DSwDBjqzYbjXfoq7oood1/k7lXuXlVWVjaiWpMtJzPKNz9yCg98egFtnd1ceudf+M4fVurezCIisp+EFnq5+z3ufrq7nwNsB9YADWY2HiB4bozTdDOxUXW/SUBdIrWkgrNnlPHMV87hivmT+Oni9Vzw/ef5n1Xx/nhERCQdJbr6ujx4ngJ8DHgIeAK4JtjlGuDxOE1fA2aY2TQzywKuCtod80rysrj18jn85rozyM6I8Lc/f40vPvg6ja2dyS5NRESSLNHzlB8xsxXAfwI3uPsO4FbgfDNbA5wfvMfMJpjZUwDBwrAvAs8AK4HfuntNgrWklHdPH8dTN57N359/Is+uaOCDdyzmp4vX0dWjhWAiIunK3FPn4hZVVVVeXV2d7DJG3fqmdm55ciX//XYjk8fmcvNFM7lodqVuBykio8LMlrh7VbLrkMPTFb1CYHpZAfde+y4e+PQC8jIzuP5Xr/Pxn77Esk07k12aiIgcRQrlEDl7RhlPfvksvn3ZqWxo3sWld/6Fzz+whFX1bckuTUREjgLdujFkMqIR/vrdU/jw3PHc/ecN3PvCBp5ZUc/Fp47nK+edyAnlBckuUUREjhAdUw65nbv3sOj59fzixVo6u3v56LyJXP/+ExTOIjJkOqacOhTKKWJbexc/fX49979US2d3H+fPquDz75vO/OPGJrs0EQk5hXLqUCinmOb2Lu5/sZb7X36Hnbu7qTpuDNedM50PzqwgGtFqbRE5mEI5dSiUU9TuPT389rVN/OzPG9iys4NJY3L55BnH8fGqyYzJz0p2eSISIgrl1KFQTnE9vX08t6KB+16q5eX128nOiHDpvAl86j1TmT2xONnliUgIKJRTh0L5GLKqvo37X6rld69voaO7l7mTS7hi/iQ+PHcCxbmZyS5PRJJEoZw6FMrHoJaObh5ZspnfVm/i7fo2sjMiXDi7ko9XTeY908cR0bFnkbSiUE4dCuVjmLvz1pYW/qN6M48v3UJrZw8TS3K5/PSJfGTeBE4oL0x2iSJyFCiUU4dCOU10dvfy7IoG/qN6Ey+sbcYdZo4v4sNzx/PhOROYPDYv2SWKyBGiUE4dCuU01NjayZNvbeU/l9Xx+sadAMydXMKH54zn4jnjGV+cm9wCRWRUKZRTh0I5zW3avntvQNfUtQKxgP7QKRVcMKtSVw4TOQYolFOHQln2Wt/UzlNvbeW5FQ0s29wCwPSyfC6YVckFp1Qwd1KJLlAikoIUyqlDoSxx1e3s4L9WNvBsTQMvr99GT58zJi+Ts2eUce5JZZw9o4yywuxklykiQ6BQTh0KZTmslt3d/Gl1I4tXN/H86iaa2/cAMHtiEeeeWM77TirjtMklZER1J1CRMFIopw6FsgxLX5+zYmsri1c38adVjby+cSe9fU5BdgbvmjqGM48v5T3Hj2Pm+CJNdYuEhEI5dSiUJSEtHd38ZW0zf1nbzEvrtrG+eRcARTkZvHv6ON4zfRxnTB/HSZWFCmmRJFEop46MZBcgqa04N5OFp45n4anjAahv6eTl9dt4ad02Xlq/jedWNABQmJPB/OPG8K6pY3nX1LHMmVRMTmY0maWLiIROQiNlM/sq8BnAgbeAvwXuA04KdikBdrr7vDhta4E2oBfoGcq/4jRSTj2bd+zmtdrtvLphB9W121nT2A5AVjTCnEnFVE0dy7zJJcybXEJlcU6SqxU5NmmknDpGPFI2s4nAl4FZ7t5hZr8FrnL3KwfscwfQcoiveb+7N4+0Bgm/SWPymDQmj8tOmwTA9l17WPLODl6r3c5rtdu554X1dPfG/mFYWZQTC+gpsZA+dWIx+dmazBGR9JHo33gZQK6ZdQN5QF3/B2ZmwMeBDyT4G3IMGZufxfmzKjh/VgUQu/zniq2tLN24k6WbYo+na+oBiBicWFHIvMklzA1CekZFAdkZmvYWkWPTiEPZ3beY2XeBjUAH8Ky7Pztgl7OBBndfM9hXAM+amQM/dfdF8XYys+uA6wCmTJky0nIlpHIyo5w+ZQynTxmzd9u29i7e3NzCG0FI/2F5Pb9+bRMAmVFjRnkhp0woYvbEYk6ZUMTM8UUaUYvIMWHEx5TNbAzwCHAlsBP4D+Bhd/9l8PlPgLXufscg7Se4e52ZlQPPAV9y9+cP9Zs6ppye3J13tu2mpq6V5XUt1NS1UrOlhW27YudLm8G00nxmTyjm5PGFnFRRyEmVhUwsySU2YSOS3nRMOXUkMrw4D9jg7k0AZvY74Ezgl2aWAXwMmD9YY3evC54bzexRYAFwyFCW9GRmTC3NZ2ppPhfPia3ydncaWrtYvqVlb1hX127niWV7j6BQkJ3BjIoCTqoo5MQgqE+qLKS0QFciE5FwSiSUNwJnmFkesenrDwL9w9jzgLfdfXO8hmaWD0TcvS14fQHwfxOoRdKMmVFZnENlcQ7nBcenAVo7u1nT0Mbb9W2srm9jVUMbz9Tsm/4GGJefxYkVhZxYUcAJ5QUcX1bA8eUFlBdma2QtIkmVyDHlV8zsYeB1oAd4A+g/LnwV8NDA/c1sAnC3uy8EKoBHg78AM4AH3f3pkdYi0q8oJ5P5x41l/nFj925zd5rb97C6oY1V9cGjoY2Hl2xm157evfsVZmcwvbyAE8oKOL48n+PLYqE9ZWwembqEqIgcBbqil6St/inwdU3trGtqZ21j7Hld4y7qWzv37pcZNaaMzWN6WQHTSvOZVprP1HH5TC/L1+haUoKOKacOLVmVtDVwCvy9J5Tu91lbZzfrm3btF9a1zbtZvLqJPT19e/fLy4oydVz+vrAu3fd6TF6mAltEhkWhLBJHYU4mc4Pzowfq63PqWjqobd7NhuZ2NgTPK7a28nRNPb19+2aeinMzmVqaz/RgZD2tLJ/jxuYxZWweJQpsEYlDoSwyDJGI7b1K2Vkz9h9dd/f2sXlHx35hXdu8m1c3bOexpVsYeKSoMDuDyUFATxmXt+/12DwmluSSlaFj2CLpSKEsMkoyo5G9U9cH6uzu5Z1tu9m4PfbYFDyvbWrnv1c17jclbgYTinOZPDaXKWPzmDxm/+Ael5+lUbbIMUqhLHIU5GRG954nfaC+PqepvSsW2Nv2D+0/rWqisa1rv/3zsqJ7R9QTx+TufZ5QksukklxKC7KJ6DaZIilJoSySZJGIUVGUQ0VRDu+aOvagzzv29LJ5x75Rdn9ob97Rwau122nr7Nlv/6xohAklOUwoyd0/uIPX44s1PS4SVgplkZDLzYoyo6KQGRUHj7IhdsGUup0dbNnRwZadwSN4vXj1wSNtMygvzB40tCeW5FKYk3k0uiYiB1Aoi6S4opxMiiozObmyKO7nXT291Ld0smVHB5uDwK4LwvutLS08W9PAnt6+/doU5mQwsSSXiqIcxhfn7Hsujj1XFuVQnKsV5CKjTaEscozLzohy3Lh8jht38AI0iB3Tbm7v2hvY/SPtrS2d1Ld2UFPXSnN710HtcjIjVBbFzvOOPefuF+CVxTmUFmQT1fFtkSFTKIukuUjEKC/KobwoZ79baA60p6ePxrZO6ls6qW8Nnls62draSUNLJ6/V7qCxbSvdvftfITAaMcoLsw8ace8L8ti2nEzdI1sEFMoiMgRZGZG952cPpq/P2bZrDw2tncEou5P6lg7qW7poaO1kdUMbz69u2u964/3G5GVSWZxLZVF28Lz/dHlFUQ5FORmaLpdjnkJZREZFJGKUFWZTVpjN7InFg+7X1tm9L7hbDhh9t3by5uZ998oeKC8resB0+cGvS/N1OpikNoWyiBxVhTmZFOZkckJ5/NXkEFuc1tjaRX0Q3g0twXNrJ1tbOnhlw3YaWjvp6dt/ujxj7+llsSnz8sJsyotyKCvMjr0uzKG8KJuxeVkKbwklhbKIhE52RpTJY2NXMRtMX5/TvKvr4NF28Hp1QxsvrG0+6DxuiIV3aUE25UWxsC4r7A/wILiD16UF2bptpxxVCmURSUmRiAUBmsOcSYPv19kdG3U3tnXS2NZFY2vwHDw27+jgjY07406ZA4zNz6KsIHvv1HxZYXbc97rJiIwGhbKIHNNyMqNMGRe7fvihdPf2sa19Tyy8W/tDu5Omtq7Yo72L2tpdNLZ17Xet8n6Z0djoe7DQHvg+L0t/9Up8+i9DRITYDUX6F4wdirvT1tWzL6wHhHb/660tnby5pYVt7V0ccNgbgPysKGWF2ftCfMDr/bdlkZ2h08XSiUJZRGQYzCx2FbWcTI4vKzjkvr19zvZdew4K7aZgFN7c3sXqhjZeXLeNlo7uuN9RlJNBaWE2377sVM6YPu5IdElCRKEsInKERAecJnY4XT29bGuPBXhzEOD7nvdQnKvrkacDhbKISAhkZ0SZUBK7Baekr4TW+pvZV82sxsyWm9lDZpZjZt80sy1mtjR4LByk7YVmtsrM1prZTYnUISIiciwYcSib2UTgy0CVu88GosBVwcffd/d5weOpOG2jwJ3ARcAs4BNmNmuktYiIiBwLEj0rPgPINbMMIA+oG2K7BcBad1/v7nuAXwOXJliLiIhIShtxKLv7FuC7wEZgK9Di7s8GH3/RzN40s3vNLN5tZyYCmwa83xxsO4iZXWdm1WZW3dTUNNJyRUREQi+R6esxxEa304AJQL6Z/Q3wE+B4YB6xsL4jXvM42+KczQfuvsjdq9y9qqysbKTlioiIhF4i09fnARvcvcndu4HfAWe6e4O797p7H/AzYlPVB9oMTB7wfhJDn/oWERE5JiUSyhuBM8wsz2IXfP0gsNLMxg/Y5zJgeZy2rwEzzGyamWURWyD2RAK1iIiIpLwRn6fs7q+Y2cPA60AP8AawCLjbzOYRm46uBT4HYGYTgLvdfaG795jZF4FniK3avtfdaxLpiIiISKoz97iHckPJzJqAd0bYvBRoHsVykkl9CZ9jpR+gvoRVIn05zt21KCcFpFQoJ8LMqt29Ktl1jAb1JXyOlX6A+hJWx1JfZHC6e7eIiEhIKJRFRERCIp1CeVGyCxhF6kv4HCv9APUlrI6lvsgg0uaYsoiISNil00hZREQk1BTKIiIiIZEWoZxK9242s8lm9j9mtjK4V/WNwfaxZvacma0JnscMaHNz0LdVZvah5FUfn5lFzewNM/t98D4l+2JmJWb2sJm9Hfzv855U7Msg90FPiX4EN7lpNLPlA7YNu3Yzm29mbwWf/TC4KmEY+nJ78N/Xm2b2qJmVDPgstH2RUeTux/SD2BXD1gHTgSxgGTAr2XUdot7xwOnB60JgNbF7Tv8bcFOw/SbgtuD1rKBP2cRuDrIOiCa7Hwf06e+BB4HfB+9Tsi/AfcBngtdZQEmq9YXY3dg2ALnB+98C16ZKP4BzgNOB5QO2Dbt24FXgPcRujvMH4KKQ9OUCICN4fVuq9EWP0Xukw0g5pe7d7O5b3f314HUbsJLYX6SXEgsFguePBq8vBX7t7l3uvgFYS/ybgCSFmU0CLgbuHrA55fpiZkXE/hK9B8Dd97j7TlKwL8S/D3pK9MPdnwe2H7B5WLUH1+cvcveX3N2B+we0OWri9cXdn3X3nuDty8Ru1gMh74uMnnQI5SHfuzlszGwqcBrwClDh7lshFtxAebBb2Pv3A+B/AX0DtqViX6YDTcDPg6n4u80snxTriw9+H/SU6scBhlv7xOD1gdvD5u+IjXwh9fsiQ5QOoTzkezeHiZkVAI8AX3H31kPtGmdbKPpnZpcAje6+ZKhN4mwLRV+IjS5PB37i7qcBu4hNlQ4mlH05xH3QB20SZ1vS+zFEg9Ue+j6Z2T8Su9HPr/o3xdktJfoiw5MOoZxy9242s0xigfwrd/9dsLmh/7aYwXNjsD3M/Xsv8BEzqyV22OADZvZLUrMvm4HN7v5K8P5hYiGdan2Jex90Uq8fAw239s3smxYeuD0UzOwa4BLg6mBKGlK0LzJ86RDKKXXv5mDl5D3ASnf/3oCPngCuCV5fAzw+YPtVZpZtZtOAGcQWfiSdu9/s7pPcfSqxP/f/dve/ITX7Ug9sMrOTgk0fBFaQen2Jex90Uq8fAw2r9mCKu83Mzgj+DD41oE1SmdmFwDeAj7j77gEfpVxfZISSvdLsaDyAhcRWMa8D/jHZ9Rym1rOITT+9CSwNHguBccAfgTXB89gBbf4x6NsqQrryEjiXfauvU7IvwDygOvjf5jFgTCr2BfhX4G1gOfAAsRW9KdEP4CFix8K7iY0SPz2S2oGqoP/rgB8RXN0wBH1ZS+zYcf//9+9Khb7oMXoPXWZTREQkJNJh+lpERCQlKJRFRERCQqEsIiISEgplERGRkFAoi4iIhIRCWUREJCQUyiIiIiHx/wFlkaZbxQwwtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses,label='train_loss')\n",
    "#plt.plot(valid_losses,label='valid_loss')\n",
    "plt.title('MSE Loss')\n",
    "#plt.ylim(0, 100)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564b712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "868b70c0",
   "metadata": {},
   "source": [
    "# Testing Set Preparation/Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b1078b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test=util.getMultiDXY(test_region.tail(6), n_lags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9702b081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7.,  5., 26., 22.,  5.,  0.,  0.,  1.,  1.,  0.,  3.,  1.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [13.,  9., 20., 85.,  4.,  2.,  0.,  2.,  8.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  8.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[13.,  9., 20., 85.,  4.,  2.,  0.,  2.,  8.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  8.,  0.,  0.,  0.],\n",
       "        [14.,  5.,  8., 10.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  3.,  0.,  2.,  0.]],\n",
       "\n",
       "       [[14.,  5.,  8., 10.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  3.,  0.,  2.,  0.],\n",
       "        [ 5.,  2.,  0., 23.,  3.,  2.,  5.,  1.,  0.,  0.,  2.,  0.,\n",
       "          0.,  0.,  0.,  3.,  4.,  0.,  4.,  0.]],\n",
       "\n",
       "       [[ 5.,  2.,  0., 23.,  3.,  2.,  5.,  1.,  0.,  0.,  2.,  0.,\n",
       "          0.,  0.,  0.,  3.,  4.,  0.,  4.,  0.],\n",
       "        [ 3.,  2.,  7., 37.,  6., 10.,  4.,  7.,  0.,  1.,  1.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a41d5a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.,  5.,  8., 10.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  3.,  0.,  2.,  0.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7d1c851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.,  5.,  8., 10.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  3.,  0.,  2.,  0.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "51b29608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.,  5.,  8., 10.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "         0.,  0.,  0.,  3.,  0.,  2.,  0.],\n",
       "       [ 5.,  2.,  0., 23.,  3.,  2.,  5.,  1.,  0.,  0.,  2.,  0.,  0.,\n",
       "         0.,  0.,  3.,  4.,  0.,  4.,  0.],\n",
       "       [ 3.,  2.,  7., 37.,  6., 10.,  4.,  7.,  0.,  1.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 7.,  6.,  7., 49.,  6.,  0.,  1.,  2.,  2.,  2.,  6.,  0.,  1.,\n",
       "         0.,  0.,  0.,  2.,  0.,  4.,  0.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6ecb2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape((x_test.shape[0], x_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1f51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31913ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prediction = []\n",
    "batch_size = 1\n",
    "iterations =  2\n",
    "\n",
    "for i in range(iterations):\n",
    "    preds = model(torch.tensor(x_test[batch_size*i:batch_size*(i+1)]).float()).detach().numpy()\n",
    "    preds = preds.reshape(1,20)\n",
    "    x_test[(i+1)][1]=preds\n",
    "    x_test[(i+2)][0]=preds\n",
    "    prediction.append(preds)\n",
    "\n",
    "prediction.append(x_test[-1][1])\n",
    "prediction.append(model(torch.tensor(x_test[-1]).float()).detach().numpy().reshape(1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0ff9f39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.0407605, 4.7688384, 4.2858334, 4.2454677, 4.841966 , 3.7707062,\n",
       "         5.5843854, 4.598163 , 3.7793   , 4.5405755, 4.9672794, 3.3013988,\n",
       "         4.709541 , 3.9104934, 4.0426517, 5.0492454, 4.699769 , 4.8730597,\n",
       "         4.64858  , 4.61479  ]], dtype=float32),\n",
       " array([[5.3125234, 6.5584283, 6.2484336, 7.5597053, 3.9907987, 6.856809 ,\n",
       "         4.8942494, 3.685001 , 4.3830457, 5.588248 , 6.2564406, 2.5953646,\n",
       "         6.8184915, 4.6243825, 6.5355234, 4.8164635, 4.761172 , 5.962522 ,\n",
       "         6.301336 , 3.3747532]], dtype=float32),\n",
       " array([ 3.,  2.,  7., 37.,  6., 10.,  4.,  7.,  0.,  1.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([[3.3503132, 4.6445336, 6.2714925, 5.7037635, 5.710345 , 4.298636 ,\n",
       "         3.3232954, 4.7895007, 5.1497107, 4.953611 , 5.5597715, 4.788865 ,\n",
       "         5.0105243, 6.285558 , 5.731327 , 4.547596 , 4.3346972, 6.1700587,\n",
       "         5.5527453, 4.8779283]], dtype=float32)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d2067db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7e55a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0ecf25b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.79518166662896\n",
      "27.313255002230495\n",
      "55.54677395614904\n",
      "92.54694801805297\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction)):\n",
    "    y_true = y_test[i]\n",
    "    y_pred = prediction[i].reshape(20)\n",
    "    print(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d36a5453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.569403444469256\n",
      "28.60557813639067\n",
      "0.0\n",
      "107.13059789990511\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction)):\n",
    "    y_true = y_test[i]\n",
    "    y_pred = prediction[i].reshape(20)\n",
    "    print(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095552f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atd2022",
   "language": "python",
   "name": "atd2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
